{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "Icm7v1F_NE-c",
        "outputId": "bbcc424d-d857-4998-8ee9-3cdb76192b5e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-55de2508-6178-4a5e-9cc5-dd2ea3d4ea81\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-55de2508-6178-4a5e-9cc5-dd2ea3d4ea81\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving data_breast_cancer.csv to data_breast_cancer.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "file = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oyt9w5ibO3oL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import f1_score\n",
        "import unittest\n",
        "import pickle\n",
        "import os\n",
        "import random\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "data = np.genfromtxt('data_breast_cancer.csv', delimiter=',')\n",
        "x = data[:, :-1] # for all but last column\n",
        "y = data[:, -1] # for last column\n",
        "\n",
        "X_train = x[:400, :]\n",
        "Y_train = y[:400]\n",
        "X_test = x[400:, :]\n",
        "Y_test = y[400:]\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFUJqFORWcot"
      },
      "source": [
        "# DNN\n",
        "\n",
        "The code below runs and creates a learning curve for the deep neural net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mgf2vLSf4ZD"
      },
      "outputs": [],
      "source": [
        "score_dict = {0: 0}\n",
        "\n",
        "for j in range(5, 401, 5):\n",
        "    print('Train data size: ', j)\n",
        "    x = X_train[0:j, :]\n",
        "    y = Y_train[0:j]\n",
        "\n",
        "    \n",
        "    classifier = Sequential() # Initialising the ANN\n",
        "    classifier.add(Dense(units = 16, activation = 'relu', input_dim = 30))\n",
        "    classifier.add(Dense(units = 8, activation = 'relu'))\n",
        "    classifier.add(Dense(units = 6, activation = 'relu'))\n",
        "    classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "    classifier.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy')\n",
        "    classifier.fit(x, y, batch_size = 1, epochs = 50)\n",
        "\n",
        "    Y_pred = classifier.predict(X_test)\n",
        "    Y_pred = [ 1 if y>=0.5 else 0 for y in Y_pred ]\n",
        "    \n",
        "    score_dict[j] = f1_score(Y_pred, Y_test)\n",
        "    print(f1_score(Y_pred, Y_test), 'Was the accuracy when the train data size was', j)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "RSFXpXnPf7Cy",
        "outputId": "fd5d10ed-d2f4-43fc-a92c-68182461e8a7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_list = sorted(score_dict.items())\n",
        "x_cord, y_cord = zip(*plot_list)\n",
        "plt.plot(x_cord, y_cord)\n",
        "plt.yticks(np.arange(min(y_cord), max(y_cord) + 0.05, 0.05))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIXZSfeG37Lb",
        "outputId": "cef99b9f-3332-4e56-f149-9b740b424651"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0, 0),\n",
              " (5, 0.7372549019607844),\n",
              " (10, 0.7782426778242678),\n",
              " (15, 0.7372549019607844),\n",
              " (20, 0.7230769230769232),\n",
              " (25, 0.714828897338403),\n",
              " (30, 0.8209606986899564),\n",
              " (35, 0.9157894736842105),\n",
              " (40, 0.8611111111111112),\n",
              " (45, 0.9183673469387754),\n",
              " (50, 0.8479262672811059),\n",
              " (55, 0.9387755102040817),\n",
              " (60, 0.9518716577540107),\n",
              " (65, 0.9479166666666666),\n",
              " (70, 0.9565217391304347),\n",
              " (75, 0.9306930693069307),\n",
              " (80, 0.9468085106382979),\n",
              " (85, 0.9393939393939394),\n",
              " (90, 0.9381443298969071),\n",
              " (95, 0.9574468085106385),\n",
              " (100, 0.9393939393939394),\n",
              " (105, 0.9690721649484536),\n",
              " (110, 0.972972972972973),\n",
              " (115, 0.972972972972973),\n",
              " (120, 0.968421052631579),\n",
              " (125, 0.9735449735449735),\n",
              " (130, 0.9680851063829787),\n",
              " (135, 0.963350785340314),\n",
              " (140, 0.9625668449197862),\n",
              " (145, 0.968421052631579),\n",
              " (150, 0.9583333333333333),\n",
              " (155, 0.9735449735449735),\n",
              " (160, 0.9583333333333333),\n",
              " (165, 0.9680851063829787),\n",
              " (170, 0.96875),\n",
              " (175, 0.9735449735449735),\n",
              " (180, 0.9591836734693878),\n",
              " (185, 0.96875),\n",
              " (190, 0.9637305699481866),\n",
              " (195, 0.9732620320855615),\n",
              " (200, 0.9543147208121827),\n",
              " (205, 0.963350785340314),\n",
              " (210, 0.96875),\n",
              " (215, 0.9740932642487047),\n",
              " (220, 0.9489795918367346),\n",
              " (225, 0.9494949494949495),\n",
              " (230, 0.967741935483871),\n",
              " (235, 0.968421052631579),\n",
              " (240, 0.968421052631579),\n",
              " (245, 0.9690721649484536),\n",
              " (250, 0.9791666666666666),\n",
              " (255, 0.96875),\n",
              " (260, 0.968421052631579),\n",
              " (265, 0.9538461538461538),\n",
              " (270, 0.9637305699481866),\n",
              " (275, 0.9690721649484536),\n",
              " (280, 0.9587628865979382),\n",
              " (285, 0.9690721649484536),\n",
              " (290, 0.9637305699481866),\n",
              " (295, 0.96875),\n",
              " (300, 0.9690721649484536),\n",
              " (305, 0.9543147208121827),\n",
              " (310, 0.96875),\n",
              " (315, 0.9641025641025642),\n",
              " (320, 0.9637305699481866),\n",
              " (325, 0.9637305699481866),\n",
              " (330, 0.968421052631579),\n",
              " (335, 0.9690721649484536),\n",
              " (340, 0.96875),\n",
              " (345, 0.96875),\n",
              " (350, 0.9591836734693878),\n",
              " (355, 0.9543147208121827),\n",
              " (360, 0.963350785340314),\n",
              " (365, 0.9690721649484536),\n",
              " (370, 0.9543147208121827),\n",
              " (375, 0.9587628865979382),\n",
              " (380, 0.9587628865979382),\n",
              " (385, 0.96875),\n",
              " (390, 0.9494949494949495),\n",
              " (395, 0.9591836734693878),\n",
              " (400, 0.9591836734693878)]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plot_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooq0tId5ebb9"
      },
      "source": [
        "Run the code above to get a test result with a chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LVQ9C3rV8tH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-k3Nxy7V8qA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adBZV2HYWneg"
      },
      "source": [
        "# ANN\n",
        "\n",
        "The code below runs a neural network with one hidden layer. This is to verify our decision tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNF7x_M0BBE9",
        "outputId": "a005f05c-283f-4de8-e5f1-0908ee4e084d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "155/155 [==============================] - 1s 4ms/step - loss: 0.1217\n",
            "0.9393939393939394 Was the accuracy when the train data size was 155\n",
            "Train data size:  160\n",
            "Epoch 1/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.8607\n",
            "Epoch 2/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.6828\n",
            "Epoch 3/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.6276\n",
            "Epoch 4/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5800\n",
            "Epoch 5/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.5371\n",
            "Epoch 6/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.4907\n",
            "Epoch 7/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.4554\n",
            "Epoch 8/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.4173\n",
            "Epoch 9/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.3845\n",
            "Epoch 10/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.3538\n",
            "Epoch 11/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.3303\n",
            "Epoch 12/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.3064\n",
            "Epoch 13/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2856\n",
            "Epoch 14/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2703\n",
            "Epoch 15/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2542\n",
            "Epoch 16/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2397\n",
            "Epoch 17/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2287\n",
            "Epoch 18/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2189\n",
            "Epoch 19/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2092\n",
            "Epoch 20/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.2036\n",
            "Epoch 21/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1951\n",
            "Epoch 22/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1903\n",
            "Epoch 23/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1806\n",
            "Epoch 24/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1804\n",
            "Epoch 25/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1781\n",
            "Epoch 26/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1753\n",
            "Epoch 27/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1673\n",
            "Epoch 28/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1655\n",
            "Epoch 29/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1604\n",
            "Epoch 30/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1573\n",
            "Epoch 31/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1555\n",
            "Epoch 32/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1517\n",
            "Epoch 33/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1505\n",
            "Epoch 34/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1486\n",
            "Epoch 35/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1473\n",
            "Epoch 36/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1469\n",
            "Epoch 37/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1439\n",
            "Epoch 38/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1434\n",
            "Epoch 39/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1389\n",
            "Epoch 40/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1364\n",
            "Epoch 41/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1380\n",
            "Epoch 42/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1336\n",
            "Epoch 43/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1328\n",
            "Epoch 44/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1342\n",
            "Epoch 45/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1312\n",
            "Epoch 46/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1308\n",
            "Epoch 47/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1255\n",
            "Epoch 48/50\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.1303\n",
            "Epoch 49/50\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 0.1279\n",
            "Epoch 50/50\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1267\n",
            "0.9393939393939394 Was the accuracy when the train data size was 160\n",
            "Train data size:  165\n",
            "Epoch 1/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.6669\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.6055\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.5665\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.5232\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.4822\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.4432\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.4082\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.3739\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.3451\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.3198\n",
            "Epoch 11/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.2943\n",
            "Epoch 12/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.2752\n",
            "Epoch 13/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.2552\n",
            "Epoch 14/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.2416\n",
            "Epoch 15/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.2272\n",
            "Epoch 16/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.2128\n",
            "Epoch 17/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.2041\n",
            "Epoch 18/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1961\n",
            "Epoch 19/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1853\n",
            "Epoch 20/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1837\n",
            "Epoch 21/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1753\n",
            "Epoch 22/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1730\n",
            "Epoch 23/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1657\n",
            "Epoch 24/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1616\n",
            "Epoch 25/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1541\n",
            "Epoch 26/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1601\n",
            "Epoch 27/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1542\n",
            "Epoch 28/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1485\n",
            "Epoch 29/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1470\n",
            "Epoch 30/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1434\n",
            "Epoch 31/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1421\n",
            "Epoch 32/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1416\n",
            "Epoch 33/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1393\n",
            "Epoch 34/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1371\n",
            "Epoch 35/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1362\n",
            "Epoch 36/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1337\n",
            "Epoch 37/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1320\n",
            "Epoch 38/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1296\n",
            "Epoch 39/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1286\n",
            "Epoch 40/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1286\n",
            "Epoch 41/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1249\n",
            "Epoch 42/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1280\n",
            "Epoch 43/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1238\n",
            "Epoch 44/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1250\n",
            "Epoch 45/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1207\n",
            "Epoch 46/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1235\n",
            "Epoch 47/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1207\n",
            "Epoch 48/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1193\n",
            "Epoch 49/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1193\n",
            "Epoch 50/50\n",
            "165/165 [==============================] - 1s 4ms/step - loss: 0.1177\n",
            "0.9441624365482233 Was the accuracy when the train data size was 165\n",
            "Train data size:  170\n",
            "Epoch 1/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.6210\n",
            "Epoch 2/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.5531\n",
            "Epoch 3/50\n",
            "170/170 [==============================] - 1s 8ms/step - loss: 0.5122\n",
            "Epoch 4/50\n",
            "170/170 [==============================] - 2s 9ms/step - loss: 0.4726\n",
            "Epoch 5/50\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.4352\n",
            "Epoch 6/50\n",
            "170/170 [==============================] - 2s 12ms/step - loss: 0.4003\n",
            "Epoch 7/50\n",
            "170/170 [==============================] - 1s 9ms/step - loss: 0.3678\n",
            "Epoch 8/50\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 0.3387\n",
            "Epoch 9/50\n",
            "170/170 [==============================] - 1s 7ms/step - loss: 0.3133\n",
            "Epoch 10/50\n",
            "170/170 [==============================] - 1s 7ms/step - loss: 0.2893\n",
            "Epoch 11/50\n",
            "170/170 [==============================] - 2s 10ms/step - loss: 0.2691\n",
            "Epoch 12/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.2503\n",
            "Epoch 13/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.2358\n",
            "Epoch 14/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.2223\n",
            "Epoch 15/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.2077\n",
            "Epoch 16/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.2042\n",
            "Epoch 17/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1885\n",
            "Epoch 18/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1853\n",
            "Epoch 19/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1791\n",
            "Epoch 20/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1723\n",
            "Epoch 21/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1658\n",
            "Epoch 22/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1624\n",
            "Epoch 23/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1549\n",
            "Epoch 24/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1539\n",
            "Epoch 25/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1463\n",
            "Epoch 26/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1505\n",
            "Epoch 27/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1448\n",
            "Epoch 28/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1417\n",
            "Epoch 29/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1398\n",
            "Epoch 30/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1347\n",
            "Epoch 31/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1384\n",
            "Epoch 32/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1338\n",
            "Epoch 33/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1331\n",
            "Epoch 34/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1315\n",
            "Epoch 35/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1297\n",
            "Epoch 36/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1301\n",
            "Epoch 37/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1275\n",
            "Epoch 38/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1260\n",
            "Epoch 39/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1249\n",
            "Epoch 40/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1232\n",
            "Epoch 41/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1226\n",
            "Epoch 42/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1216\n",
            "Epoch 43/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1237\n",
            "Epoch 44/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1223\n",
            "Epoch 45/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1174\n",
            "Epoch 46/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1168\n",
            "Epoch 47/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1191\n",
            "Epoch 48/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1148\n",
            "Epoch 49/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1135\n",
            "Epoch 50/50\n",
            "170/170 [==============================] - 1s 4ms/step - loss: 0.1137\n",
            "0.9587628865979382 Was the accuracy when the train data size was 170\n",
            "Train data size:  175\n",
            "Epoch 1/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.6222\n",
            "Epoch 2/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5659\n",
            "Epoch 3/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.5140\n",
            "Epoch 4/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.4703\n",
            "Epoch 5/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.4291\n",
            "Epoch 6/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.3918\n",
            "Epoch 7/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.3616\n",
            "Epoch 8/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.3316\n",
            "Epoch 9/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.3069\n",
            "Epoch 10/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.2833\n",
            "Epoch 11/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.2640\n",
            "Epoch 12/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.2493\n",
            "Epoch 13/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.2351\n",
            "Epoch 14/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.2218\n",
            "Epoch 15/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.2100\n",
            "Epoch 16/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.2017\n",
            "Epoch 17/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1914\n",
            "Epoch 18/50\n",
            "175/175 [==============================] - 1s 4ms/step - loss: 0.1866\n",
            "Epoch 19/50\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.1811\n",
            "Epoch 20/50\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1724\n",
            "Epoch 21/50\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.1688\n",
            "Epoch 22/50\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1653\n",
            "Epoch 23/50\n",
            "175/175 [==============================] - 1s 8ms/step - loss: 0.1586\n",
            "Epoch 24/50\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1555\n",
            "Epoch 25/50\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.1534\n",
            "Epoch 26/50\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.1494\n",
            "Epoch 27/50\n",
            "175/175 [==============================] - 1s 8ms/step - loss: 0.1480\n",
            "Epoch 28/50\n",
            "175/175 [==============================] - 1s 7ms/step - loss: 0.1442\n",
            "Epoch 29/50\n",
            "175/175 [==============================] - 2s 9ms/step - loss: 0.1431\n",
            "Epoch 30/50\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1375\n",
            "Epoch 31/50\n",
            "175/175 [==============================] - 2s 9ms/step - loss: 0.1411\n",
            "Epoch 32/50\n",
            "175/175 [==============================] - 1s 7ms/step - loss: 0.1345\n",
            "Epoch 33/50\n",
            "175/175 [==============================] - 1s 7ms/step - loss: 0.1351\n",
            "Epoch 34/50\n",
            "175/175 [==============================] - 1s 8ms/step - loss: 0.1331\n",
            "Epoch 35/50\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1328\n",
            "Epoch 36/50\n",
            "175/175 [==============================] - 1s 7ms/step - loss: 0.1257\n",
            "Epoch 37/50\n",
            "175/175 [==============================] - 1s 7ms/step - loss: 0.1266\n",
            "Epoch 38/50\n",
            "175/175 [==============================] - 1s 7ms/step - loss: 0.1300\n",
            "Epoch 39/50\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 0.1267\n",
            "Epoch 40/50\n",
            "175/175 [==============================] - 2s 9ms/step - loss: 0.1244\n",
            "Epoch 41/50\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1226\n",
            "Epoch 42/50\n",
            "175/175 [==============================] - 2s 9ms/step - loss: 0.1208\n",
            "Epoch 43/50\n",
            "175/175 [==============================] - 1s 7ms/step - loss: 0.1193\n",
            "Epoch 44/50\n",
            "175/175 [==============================] - 1s 8ms/step - loss: 0.1221\n",
            "Epoch 45/50\n",
            "175/175 [==============================] - 1s 7ms/step - loss: 0.1203\n",
            "Epoch 46/50\n",
            "175/175 [==============================] - 1s 6ms/step - loss: 0.1176\n",
            "Epoch 47/50\n",
            "175/175 [==============================] - 1s 7ms/step - loss: 0.1173\n",
            "Epoch 48/50\n",
            "175/175 [==============================] - 1s 7ms/step - loss: 0.1157\n",
            "Epoch 49/50\n",
            "175/175 [==============================] - 1s 5ms/step - loss: 0.1181\n",
            "Epoch 50/50\n",
            "175/175 [==============================] - 1s 8ms/step - loss: 0.1132\n",
            "0.9346733668341708 Was the accuracy when the train data size was 175\n",
            "Train data size:  180\n",
            "Epoch 1/50\n",
            "180/180 [==============================] - 1s 5ms/step - loss: 0.6299\n",
            "Epoch 2/50\n",
            "180/180 [==============================] - 2s 10ms/step - loss: 0.5821\n",
            "Epoch 3/50\n",
            "180/180 [==============================] - 1s 8ms/step - loss: 0.5377\n",
            "Epoch 4/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.4995\n",
            "Epoch 5/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.4594\n",
            "Epoch 6/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.4201\n",
            "Epoch 7/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.3873\n",
            "Epoch 8/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.3529\n",
            "Epoch 9/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.3266\n",
            "Epoch 10/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.3021\n",
            "Epoch 11/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.2793\n",
            "Epoch 12/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.2603\n",
            "Epoch 13/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.2421\n",
            "Epoch 14/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.2287\n",
            "Epoch 15/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.2162\n",
            "Epoch 16/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.2050\n",
            "Epoch 17/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1956\n",
            "Epoch 18/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1880\n",
            "Epoch 19/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1797\n",
            "Epoch 20/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1748\n",
            "Epoch 21/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1699\n",
            "Epoch 22/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1656\n",
            "Epoch 23/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1610\n",
            "Epoch 24/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1552\n",
            "Epoch 25/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1511\n",
            "Epoch 26/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1501\n",
            "Epoch 27/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1456\n",
            "Epoch 28/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1430\n",
            "Epoch 29/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1424\n",
            "Epoch 30/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1413\n",
            "Epoch 31/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1371\n",
            "Epoch 32/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1355\n",
            "Epoch 33/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1354\n",
            "Epoch 34/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1328\n",
            "Epoch 35/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1298\n",
            "Epoch 36/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1267\n",
            "Epoch 37/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1241\n",
            "Epoch 38/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1250\n",
            "Epoch 39/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1247\n",
            "Epoch 40/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1240\n",
            "Epoch 41/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1208\n",
            "Epoch 42/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1210\n",
            "Epoch 43/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1195\n",
            "Epoch 44/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1181\n",
            "Epoch 45/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1176\n",
            "Epoch 46/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1150\n",
            "Epoch 47/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1146\n",
            "Epoch 48/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1135\n",
            "Epoch 49/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1110\n",
            "Epoch 50/50\n",
            "180/180 [==============================] - 1s 4ms/step - loss: 0.1126\n",
            "0.9489795918367346 Was the accuracy when the train data size was 180\n",
            "Train data size:  185\n",
            "Epoch 1/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.6701\n",
            "Epoch 2/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.6105\n",
            "Epoch 3/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.5617\n",
            "Epoch 4/50\n",
            "185/185 [==============================] - 1s 6ms/step - loss: 0.5124\n",
            "Epoch 5/50\n",
            "185/185 [==============================] - 1s 5ms/step - loss: 0.4769\n",
            "Epoch 6/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.4369\n",
            "Epoch 7/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.4000\n",
            "Epoch 8/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.3655\n",
            "Epoch 9/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.3376\n",
            "Epoch 10/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.3104\n",
            "Epoch 11/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.2867\n",
            "Epoch 12/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.2654\n",
            "Epoch 13/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.2471\n",
            "Epoch 14/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.2333\n",
            "Epoch 15/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.2197\n",
            "Epoch 16/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.2076\n",
            "Epoch 17/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.2000\n",
            "Epoch 18/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1913\n",
            "Epoch 19/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1841\n",
            "Epoch 20/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1785\n",
            "Epoch 21/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1705\n",
            "Epoch 22/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1672\n",
            "Epoch 23/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1610\n",
            "Epoch 24/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1560\n",
            "Epoch 25/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1496\n",
            "Epoch 26/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1520\n",
            "Epoch 27/50\n",
            "185/185 [==============================] - 1s 5ms/step - loss: 0.1478\n",
            "Epoch 28/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1466\n",
            "Epoch 29/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1426\n",
            "Epoch 30/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1371\n",
            "Epoch 31/50\n",
            "185/185 [==============================] - 1s 3ms/step - loss: 0.1396\n",
            "Epoch 32/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1371\n",
            "Epoch 33/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1315\n",
            "Epoch 34/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1348\n",
            "Epoch 35/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1301\n",
            "Epoch 36/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1279\n",
            "Epoch 37/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1259\n",
            "Epoch 38/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1279\n",
            "Epoch 39/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1259\n",
            "Epoch 40/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1235\n",
            "Epoch 41/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1253\n",
            "Epoch 42/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1208\n",
            "Epoch 43/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1211\n",
            "Epoch 44/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1209\n",
            "Epoch 45/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1182\n",
            "Epoch 46/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1182\n",
            "Epoch 47/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1174\n",
            "Epoch 48/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1157\n",
            "Epoch 49/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1148\n",
            "Epoch 50/50\n",
            "185/185 [==============================] - 1s 4ms/step - loss: 0.1156\n",
            "0.9489795918367346 Was the accuracy when the train data size was 185\n",
            "Train data size:  190\n",
            "Epoch 1/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.7192\n",
            "Epoch 2/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.6386\n",
            "Epoch 3/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.5953\n",
            "Epoch 4/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.5505\n",
            "Epoch 5/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.5053\n",
            "Epoch 6/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.4653\n",
            "Epoch 7/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.4238\n",
            "Epoch 8/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.3858\n",
            "Epoch 9/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.3500\n",
            "Epoch 10/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.3196\n",
            "Epoch 11/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.2915\n",
            "Epoch 12/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.2687\n",
            "Epoch 13/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.2485\n",
            "Epoch 14/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.2362\n",
            "Epoch 15/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.2203\n",
            "Epoch 16/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.2076\n",
            "Epoch 17/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1959\n",
            "Epoch 18/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1871\n",
            "Epoch 19/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1809\n",
            "Epoch 20/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1748\n",
            "Epoch 21/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1677\n",
            "Epoch 22/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1629\n",
            "Epoch 23/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1562\n",
            "Epoch 24/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1532\n",
            "Epoch 25/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1515\n",
            "Epoch 26/50\n",
            "190/190 [==============================] - 1s 8ms/step - loss: 0.1482\n",
            "Epoch 27/50\n",
            "190/190 [==============================] - 1s 7ms/step - loss: 0.1438\n",
            "Epoch 28/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1414\n",
            "Epoch 29/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1392\n",
            "Epoch 30/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1341\n",
            "Epoch 31/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1347\n",
            "Epoch 32/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1300\n",
            "Epoch 33/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1290\n",
            "Epoch 34/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1221\n",
            "Epoch 35/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1288\n",
            "Epoch 36/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1247\n",
            "Epoch 37/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1215\n",
            "Epoch 38/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1208\n",
            "Epoch 39/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1191\n",
            "Epoch 40/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1181\n",
            "Epoch 41/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1165\n",
            "Epoch 42/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1139\n",
            "Epoch 43/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1142\n",
            "Epoch 44/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1140\n",
            "Epoch 45/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1118\n",
            "Epoch 46/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1137\n",
            "Epoch 47/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1109\n",
            "Epoch 48/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1094\n",
            "Epoch 49/50\n",
            "190/190 [==============================] - 1s 4ms/step - loss: 0.1090\n",
            "Epoch 50/50\n",
            "190/190 [==============================] - 1s 8ms/step - loss: 0.1080\n",
            "0.9441624365482233 Was the accuracy when the train data size was 190\n",
            "Train data size:  195\n",
            "Epoch 1/50\n",
            "195/195 [==============================] - 2s 7ms/step - loss: 0.6523\n",
            "Epoch 2/50\n",
            "195/195 [==============================] - 1s 5ms/step - loss: 0.5918\n",
            "Epoch 3/50\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.5442\n",
            "Epoch 4/50\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4959\n",
            "Epoch 5/50\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.4546\n",
            "Epoch 6/50\n",
            "195/195 [==============================] - 2s 11ms/step - loss: 0.4161\n",
            "Epoch 7/50\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3801\n",
            "Epoch 8/50\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.3495\n",
            "Epoch 9/50\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.3214\n",
            "Epoch 10/50\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2945\n",
            "Epoch 11/50\n",
            "195/195 [==============================] - 1s 5ms/step - loss: 0.2717\n",
            "Epoch 12/50\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.2509\n",
            "Epoch 13/50\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.2346\n",
            "Epoch 14/50\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.2214\n",
            "Epoch 15/50\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.2098\n",
            "Epoch 16/50\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.1984\n",
            "Epoch 17/50\n",
            "195/195 [==============================] - 1s 8ms/step - loss: 0.1902\n",
            "Epoch 18/50\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.1835\n",
            "Epoch 19/50\n",
            "195/195 [==============================] - 2s 9ms/step - loss: 0.1763\n",
            "Epoch 20/50\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.1692\n",
            "Epoch 21/50\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.1651\n",
            "Epoch 22/50\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.1600\n",
            "Epoch 23/50\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.1566\n",
            "Epoch 24/50\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.1542\n",
            "Epoch 25/50\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.1481\n",
            "Epoch 26/50\n",
            "195/195 [==============================] - 1s 8ms/step - loss: 0.1453\n",
            "Epoch 27/50\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.1427\n",
            "Epoch 28/50\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.1409\n",
            "Epoch 29/50\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.1397\n",
            "Epoch 30/50\n",
            "195/195 [==============================] - 1s 5ms/step - loss: 0.1383\n",
            "Epoch 31/50\n",
            "195/195 [==============================] - 1s 5ms/step - loss: 0.1354\n",
            "Epoch 32/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1319\n",
            "Epoch 33/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1277\n",
            "Epoch 34/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1292\n",
            "Epoch 35/50\n",
            "195/195 [==============================] - 1s 7ms/step - loss: 0.1242\n",
            "Epoch 36/50\n",
            "195/195 [==============================] - 1s 6ms/step - loss: 0.1245\n",
            "Epoch 37/50\n",
            "195/195 [==============================] - 1s 5ms/step - loss: 0.1232\n",
            "Epoch 38/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1219\n",
            "Epoch 39/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1191\n",
            "Epoch 40/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1192\n",
            "Epoch 41/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1164\n",
            "Epoch 42/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1154\n",
            "Epoch 43/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1166\n",
            "Epoch 44/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1129\n",
            "Epoch 45/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1119\n",
            "Epoch 46/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1122\n",
            "Epoch 47/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1104\n",
            "Epoch 48/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1100\n",
            "Epoch 49/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1109\n",
            "Epoch 50/50\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.1106\n",
            "0.9441624365482233 Was the accuracy when the train data size was 195\n",
            "Train data size:  200\n",
            "Epoch 1/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.6274\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.5591\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4999\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4512\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4024\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3686\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3298\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3070\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2829\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2582\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2410\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2249\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2130\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1969\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1919\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1818\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1734\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1662\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1613\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1565\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1503\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1504\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1455\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1409\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1392\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1376\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1335\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1316\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1277\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1267\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1267\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.1222\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1220\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1205\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1165\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1184\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1129\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1140\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1109\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1123\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1123\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1101\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1081\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1071\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1066\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1050\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1052\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1050\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1040\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.1027\n",
            "0.9441624365482233 Was the accuracy when the train data size was 200\n",
            "Train data size:  205\n",
            "Epoch 1/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.6220\n",
            "Epoch 2/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.5665\n",
            "Epoch 3/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.5119\n",
            "Epoch 4/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.4636\n",
            "Epoch 5/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.4171\n",
            "Epoch 6/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.3784\n",
            "Epoch 7/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.3414\n",
            "Epoch 8/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.3101\n",
            "Epoch 9/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.2819\n",
            "Epoch 10/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.2554\n",
            "Epoch 11/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.2384\n",
            "Epoch 12/50\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.2207\n",
            "Epoch 13/50\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.1982\n",
            "Epoch 14/50\n",
            "205/205 [==============================] - 2s 8ms/step - loss: 0.1966\n",
            "Epoch 15/50\n",
            "205/205 [==============================] - 2s 10ms/step - loss: 0.1838\n",
            "Epoch 16/50\n",
            "205/205 [==============================] - 2s 10ms/step - loss: 0.1752\n",
            "Epoch 17/50\n",
            "205/205 [==============================] - 1s 6ms/step - loss: 0.1670\n",
            "Epoch 18/50\n",
            "205/205 [==============================] - 2s 9ms/step - loss: 0.1607\n",
            "Epoch 19/50\n",
            "205/205 [==============================] - 2s 10ms/step - loss: 0.1553\n",
            "Epoch 20/50\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.1504\n",
            "Epoch 21/50\n",
            "205/205 [==============================] - 1s 6ms/step - loss: 0.1447\n",
            "Epoch 22/50\n",
            "205/205 [==============================] - 2s 10ms/step - loss: 0.1415\n",
            "Epoch 23/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.1369\n",
            "Epoch 24/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.1363\n",
            "Epoch 25/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.1319\n",
            "Epoch 26/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.1286\n",
            "Epoch 27/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.1283\n",
            "Epoch 28/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.1256\n",
            "Epoch 29/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.1225\n",
            "Epoch 30/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.1199\n",
            "Epoch 31/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.1200\n",
            "Epoch 32/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.1172\n",
            "Epoch 33/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.1166\n",
            "Epoch 34/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.1110\n",
            "Epoch 35/50\n",
            "205/205 [==============================] - 1s 4ms/step - loss: 0.1141\n",
            "Epoch 36/50\n",
            "205/205 [==============================] - 2s 8ms/step - loss: 0.1128\n",
            "Epoch 37/50\n",
            "205/205 [==============================] - 2s 8ms/step - loss: 0.1130\n",
            "Epoch 38/50\n",
            "205/205 [==============================] - 2s 10ms/step - loss: 0.1118\n",
            "Epoch 39/50\n",
            "205/205 [==============================] - 2s 11ms/step - loss: 0.1065\n",
            "Epoch 40/50\n",
            "205/205 [==============================] - 2s 8ms/step - loss: 0.1097\n",
            "Epoch 41/50\n",
            "205/205 [==============================] - 2s 7ms/step - loss: 0.1088\n",
            "Epoch 42/50\n",
            "205/205 [==============================] - 2s 9ms/step - loss: 0.1084\n",
            "Epoch 43/50\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.1054\n",
            "Epoch 44/50\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.1078\n",
            "Epoch 45/50\n",
            "205/205 [==============================] - 2s 8ms/step - loss: 0.1054\n",
            "Epoch 46/50\n",
            "205/205 [==============================] - 2s 8ms/step - loss: 0.1061\n",
            "Epoch 47/50\n",
            "205/205 [==============================] - 1s 7ms/step - loss: 0.1025\n",
            "Epoch 48/50\n",
            "205/205 [==============================] - 1s 6ms/step - loss: 0.1035\n",
            "Epoch 49/50\n",
            "205/205 [==============================] - 1s 5ms/step - loss: 0.1010\n",
            "Epoch 50/50\n",
            "205/205 [==============================] - 1s 6ms/step - loss: 0.0998\n",
            "0.9393939393939394 Was the accuracy when the train data size was 205\n",
            "Train data size:  210\n",
            "Epoch 1/50\n",
            "210/210 [==============================] - 3s 10ms/step - loss: 0.6243\n",
            "Epoch 2/50\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 0.5628\n",
            "Epoch 3/50\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.5079\n",
            "Epoch 4/50\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.4585\n",
            "Epoch 5/50\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 0.4091\n",
            "Epoch 6/50\n",
            "210/210 [==============================] - 1s 6ms/step - loss: 0.3675\n",
            "Epoch 7/50\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.3289\n",
            "Epoch 8/50\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.2965\n",
            "Epoch 9/50\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.2680\n",
            "Epoch 10/50\n",
            "210/210 [==============================] - 1s 6ms/step - loss: 0.2452\n",
            "Epoch 11/50\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.2259\n",
            "Epoch 12/50\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.2086\n",
            "Epoch 13/50\n",
            "210/210 [==============================] - 1s 6ms/step - loss: 0.1950\n",
            "Epoch 14/50\n",
            "210/210 [==============================] - 1s 6ms/step - loss: 0.1817\n",
            "Epoch 15/50\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 0.1747\n",
            "Epoch 16/50\n",
            "210/210 [==============================] - 1s 6ms/step - loss: 0.1638\n",
            "Epoch 17/50\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.1589\n",
            "Epoch 18/50\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1488\n",
            "Epoch 19/50\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 0.1474\n",
            "Epoch 20/50\n",
            "210/210 [==============================] - 1s 6ms/step - loss: 0.1414\n",
            "Epoch 21/50\n",
            "210/210 [==============================] - 2s 10ms/step - loss: 0.1409\n",
            "Epoch 22/50\n",
            "210/210 [==============================] - 1s 6ms/step - loss: 0.1343\n",
            "Epoch 23/50\n",
            "210/210 [==============================] - 1s 6ms/step - loss: 0.1342\n",
            "Epoch 24/50\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.1293\n",
            "Epoch 25/50\n",
            "210/210 [==============================] - 1s 6ms/step - loss: 0.1267\n",
            "Epoch 26/50\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1243\n",
            "Epoch 27/50\n",
            "210/210 [==============================] - 1s 6ms/step - loss: 0.1222\n",
            "Epoch 28/50\n",
            "210/210 [==============================] - 1s 6ms/step - loss: 0.1206\n",
            "Epoch 29/50\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.1190\n",
            "Epoch 30/50\n",
            "210/210 [==============================] - 2s 10ms/step - loss: 0.1172\n",
            "Epoch 31/50\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.1172\n",
            "Epoch 32/50\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 0.1150\n",
            "Epoch 33/50\n",
            "210/210 [==============================] - 2s 9ms/step - loss: 0.1133\n",
            "Epoch 34/50\n",
            "210/210 [==============================] - 2s 10ms/step - loss: 0.1104\n",
            "Epoch 35/50\n",
            "210/210 [==============================] - 2s 7ms/step - loss: 0.1106\n",
            "Epoch 36/50\n",
            "210/210 [==============================] - 1s 6ms/step - loss: 0.1058\n",
            "Epoch 37/50\n",
            "210/210 [==============================] - 1s 6ms/step - loss: 0.1085\n",
            "Epoch 38/50\n",
            "210/210 [==============================] - 1s 4ms/step - loss: 0.1069\n",
            "Epoch 39/50\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.1078\n",
            "Epoch 40/50\n",
            "210/210 [==============================] - 2s 8ms/step - loss: 0.1039\n",
            "Epoch 41/50\n",
            "210/210 [==============================] - 2s 9ms/step - loss: 0.1038\n",
            "Epoch 42/50\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.1019\n",
            "Epoch 43/50\n",
            "210/210 [==============================] - 1s 5ms/step - loss: 0.1017\n",
            "Epoch 44/50\n",
            "210/210 [==============================] - 2s 10ms/step - loss: 0.1021\n",
            "Epoch 45/50\n",
            "210/210 [==============================] - 2s 11ms/step - loss: 0.1006\n",
            "Epoch 46/50\n",
            "210/210 [==============================] - 2s 10ms/step - loss: 0.0982\n",
            "Epoch 47/50\n",
            "210/210 [==============================] - 2s 9ms/step - loss: 0.0968\n",
            "Epoch 48/50\n",
            "210/210 [==============================] - 1s 7ms/step - loss: 0.0988\n",
            "Epoch 49/50\n",
            "210/210 [==============================] - 2s 11ms/step - loss: 0.0981\n",
            "Epoch 50/50\n",
            "210/210 [==============================] - 2s 10ms/step - loss: 0.0974\n",
            "0.9587628865979382 Was the accuracy when the train data size was 210\n",
            "Train data size:  215\n",
            "Epoch 1/50\n",
            "215/215 [==============================] - 2s 5ms/step - loss: 0.6213\n",
            "Epoch 2/50\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.5543\n",
            "Epoch 3/50\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.4977\n",
            "Epoch 4/50\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.4445\n",
            "Epoch 5/50\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.3989\n",
            "Epoch 6/50\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.3585\n",
            "Epoch 7/50\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.3232\n",
            "Epoch 8/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2886\n",
            "Epoch 9/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2643\n",
            "Epoch 10/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2416\n",
            "Epoch 11/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2195\n",
            "Epoch 12/50\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.2073\n",
            "Epoch 13/50\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1929\n",
            "Epoch 14/50\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1769\n",
            "Epoch 15/50\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1740\n",
            "Epoch 16/50\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1643\n",
            "Epoch 17/50\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.1567\n",
            "Epoch 18/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1529\n",
            "Epoch 19/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1455\n",
            "Epoch 20/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1429\n",
            "Epoch 21/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1390\n",
            "Epoch 22/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1355\n",
            "Epoch 23/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1317\n",
            "Epoch 24/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1297\n",
            "Epoch 25/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1260\n",
            "Epoch 26/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1242\n",
            "Epoch 27/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1215\n",
            "Epoch 28/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1186\n",
            "Epoch 29/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1160\n",
            "Epoch 30/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1172\n",
            "Epoch 31/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1139\n",
            "Epoch 32/50\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.1118\n",
            "Epoch 33/50\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1118\n",
            "Epoch 34/50\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.1130\n",
            "Epoch 35/50\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1087\n",
            "Epoch 36/50\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.1104\n",
            "Epoch 37/50\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.1092\n",
            "Epoch 38/50\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1065\n",
            "Epoch 39/50\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.1056\n",
            "Epoch 40/50\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1040\n",
            "Epoch 41/50\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.1002\n",
            "Epoch 42/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1045\n",
            "Epoch 43/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1011\n",
            "Epoch 44/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1027\n",
            "Epoch 45/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1008\n",
            "Epoch 46/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.0955\n",
            "Epoch 47/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.1024\n",
            "Epoch 48/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.0984\n",
            "Epoch 49/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.0997\n",
            "Epoch 50/50\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.0961\n",
            "0.9393939393939394 Was the accuracy when the train data size was 215\n",
            "Train data size:  220\n",
            "Epoch 1/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.6738\n",
            "Epoch 2/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5968\n",
            "Epoch 3/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.5314\n",
            "Epoch 4/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4718\n",
            "Epoch 5/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.4217\n",
            "Epoch 6/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.3760\n",
            "Epoch 7/50\n",
            "220/220 [==============================] - 2s 7ms/step - loss: 0.3353\n",
            "Epoch 8/50\n",
            "220/220 [==============================] - 2s 10ms/step - loss: 0.3049\n",
            "Epoch 9/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.2786\n",
            "Epoch 10/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.2550\n",
            "Epoch 11/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.2365\n",
            "Epoch 12/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.2183\n",
            "Epoch 13/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.2063\n",
            "Epoch 14/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1951\n",
            "Epoch 15/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1839\n",
            "Epoch 16/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1750\n",
            "Epoch 17/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1677\n",
            "Epoch 18/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1617\n",
            "Epoch 19/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1570\n",
            "Epoch 20/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1498\n",
            "Epoch 21/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1460\n",
            "Epoch 22/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1418\n",
            "Epoch 23/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1375\n",
            "Epoch 24/50\n",
            "220/220 [==============================] - 2s 8ms/step - loss: 0.1366\n",
            "Epoch 25/50\n",
            "220/220 [==============================] - 2s 8ms/step - loss: 0.1321\n",
            "Epoch 26/50\n",
            "220/220 [==============================] - 2s 8ms/step - loss: 0.1287\n",
            "Epoch 27/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1267\n",
            "Epoch 28/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1253\n",
            "Epoch 29/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1224\n",
            "Epoch 30/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1242\n",
            "Epoch 31/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1177\n",
            "Epoch 32/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1185\n",
            "Epoch 33/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1128\n",
            "Epoch 34/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1149\n",
            "Epoch 35/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1127\n",
            "Epoch 36/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1103\n",
            "Epoch 37/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1091\n",
            "Epoch 38/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1121\n",
            "Epoch 39/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1051\n",
            "Epoch 40/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1048\n",
            "Epoch 41/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1044\n",
            "Epoch 42/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 0.1044\n",
            "Epoch 43/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1013\n",
            "Epoch 44/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.0990\n",
            "Epoch 45/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.1009\n",
            "Epoch 46/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.0978\n",
            "Epoch 47/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.0979\n",
            "Epoch 48/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.0973\n",
            "Epoch 49/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.0954\n",
            "Epoch 50/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 0.0968\n",
            "0.9253731343283582 Was the accuracy when the train data size was 220\n",
            "Train data size:  225\n",
            "Epoch 1/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6785\n",
            "Epoch 2/50\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.5931\n",
            "Epoch 3/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.5384\n",
            "Epoch 4/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.4834\n",
            "Epoch 5/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.4328\n",
            "Epoch 6/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.3877\n",
            "Epoch 7/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.3469\n",
            "Epoch 8/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.3102\n",
            "Epoch 9/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.2817\n",
            "Epoch 10/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.2549\n",
            "Epoch 11/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.2357\n",
            "Epoch 12/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.2152\n",
            "Epoch 13/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.2005\n",
            "Epoch 14/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.1880\n",
            "Epoch 15/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.1785\n",
            "Epoch 16/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.1695\n",
            "Epoch 17/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.1612\n",
            "Epoch 18/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.1556\n",
            "Epoch 19/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.1496\n",
            "Epoch 20/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.1450\n",
            "Epoch 21/50\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.1405\n",
            "Epoch 22/50\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.1381\n",
            "Epoch 23/50\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.1308\n",
            "Epoch 24/50\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.1344\n",
            "Epoch 25/50\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.1248\n",
            "Epoch 26/50\n",
            "225/225 [==============================] - 2s 9ms/step - loss: 0.1250\n",
            "Epoch 27/50\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.1224\n",
            "Epoch 28/50\n",
            "225/225 [==============================] - 2s 9ms/step - loss: 0.1219\n",
            "Epoch 29/50\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1189\n",
            "Epoch 30/50\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.1173\n",
            "Epoch 31/50\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 0.1156\n",
            "Epoch 32/50\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.1152\n",
            "Epoch 33/50\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 0.1137\n",
            "Epoch 34/50\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.1110\n",
            "Epoch 35/50\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 0.1111\n",
            "Epoch 36/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.1067\n",
            "Epoch 37/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.1067\n",
            "Epoch 38/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.1054\n",
            "Epoch 39/50\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.1050\n",
            "Epoch 40/50\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.1023\n",
            "Epoch 41/50\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.1004\n",
            "Epoch 42/50\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 0.0993\n",
            "Epoch 43/50\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.0986\n",
            "Epoch 44/50\n",
            "225/225 [==============================] - 2s 9ms/step - loss: 0.0990\n",
            "Epoch 45/50\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 0.0999\n",
            "Epoch 46/50\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.0967\n",
            "Epoch 47/50\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.0941\n",
            "Epoch 48/50\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 0.0931\n",
            "Epoch 49/50\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.0928\n",
            "Epoch 50/50\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.0923\n",
            "0.9489795918367346 Was the accuracy when the train data size was 225\n",
            "Train data size:  230\n",
            "Epoch 1/50\n",
            "230/230 [==============================] - 3s 5ms/step - loss: 0.6184\n",
            "Epoch 2/50\n",
            "230/230 [==============================] - 2s 7ms/step - loss: 0.5462\n",
            "Epoch 3/50\n",
            "230/230 [==============================] - 2s 7ms/step - loss: 0.4872\n",
            "Epoch 4/50\n",
            "230/230 [==============================] - 1s 6ms/step - loss: 0.4335\n",
            "Epoch 5/50\n",
            "230/230 [==============================] - 1s 6ms/step - loss: 0.3843\n",
            "Epoch 6/50\n",
            "230/230 [==============================] - 1s 6ms/step - loss: 0.3429\n",
            "Epoch 7/50\n",
            "230/230 [==============================] - 1s 6ms/step - loss: 0.3063\n",
            "Epoch 8/50\n",
            "230/230 [==============================] - 1s 5ms/step - loss: 0.2756\n",
            "Epoch 9/50\n",
            "230/230 [==============================] - 1s 5ms/step - loss: 0.2501\n",
            "Epoch 10/50\n",
            "230/230 [==============================] - 2s 7ms/step - loss: 0.2274\n",
            "Epoch 11/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.2074\n",
            "Epoch 12/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.1954\n",
            "Epoch 13/50\n",
            "230/230 [==============================] - 1s 3ms/step - loss: 0.1831\n",
            "Epoch 14/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.1717\n",
            "Epoch 15/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.1645\n",
            "Epoch 16/50\n",
            "230/230 [==============================] - 1s 5ms/step - loss: 0.1598\n",
            "Epoch 17/50\n",
            "230/230 [==============================] - 1s 6ms/step - loss: 0.1504\n",
            "Epoch 18/50\n",
            "230/230 [==============================] - 1s 6ms/step - loss: 0.1443\n",
            "Epoch 19/50\n",
            "230/230 [==============================] - 1s 5ms/step - loss: 0.1397\n",
            "Epoch 20/50\n",
            "230/230 [==============================] - 1s 5ms/step - loss: 0.1375\n",
            "Epoch 21/50\n",
            "230/230 [==============================] - 1s 5ms/step - loss: 0.1304\n",
            "Epoch 22/50\n",
            "230/230 [==============================] - 1s 5ms/step - loss: 0.1313\n",
            "Epoch 23/50\n",
            "230/230 [==============================] - 1s 6ms/step - loss: 0.1269\n",
            "Epoch 24/50\n",
            "230/230 [==============================] - 2s 7ms/step - loss: 0.1268\n",
            "Epoch 25/50\n",
            "230/230 [==============================] - 1s 6ms/step - loss: 0.1230\n",
            "Epoch 26/50\n",
            "230/230 [==============================] - 2s 9ms/step - loss: 0.1180\n",
            "Epoch 27/50\n",
            "230/230 [==============================] - 1s 6ms/step - loss: 0.1195\n",
            "Epoch 28/50\n",
            "230/230 [==============================] - 1s 5ms/step - loss: 0.1169\n",
            "Epoch 29/50\n",
            "230/230 [==============================] - 1s 5ms/step - loss: 0.1155\n",
            "Epoch 30/50\n",
            "230/230 [==============================] - 1s 6ms/step - loss: 0.1102\n",
            "Epoch 31/50\n",
            "230/230 [==============================] - 2s 8ms/step - loss: 0.1128\n",
            "Epoch 32/50\n",
            "230/230 [==============================] - 2s 7ms/step - loss: 0.1080\n",
            "Epoch 33/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.1093\n",
            "Epoch 34/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.1084\n",
            "Epoch 35/50\n",
            "230/230 [==============================] - 1s 5ms/step - loss: 0.1063\n",
            "Epoch 36/50\n",
            "230/230 [==============================] - 1s 6ms/step - loss: 0.1045\n",
            "Epoch 37/50\n",
            "230/230 [==============================] - 2s 7ms/step - loss: 0.1039\n",
            "Epoch 38/50\n",
            "230/230 [==============================] - 2s 7ms/step - loss: 0.1035\n",
            "Epoch 39/50\n",
            "230/230 [==============================] - 1s 6ms/step - loss: 0.1025\n",
            "Epoch 40/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.1023\n",
            "Epoch 41/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.1010\n",
            "Epoch 42/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.0992\n",
            "Epoch 43/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.0979\n",
            "Epoch 44/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.0975\n",
            "Epoch 45/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.0972\n",
            "Epoch 46/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.0947\n",
            "Epoch 47/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.0931\n",
            "Epoch 48/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.0961\n",
            "Epoch 49/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.0938\n",
            "Epoch 50/50\n",
            "230/230 [==============================] - 1s 4ms/step - loss: 0.0939\n",
            "0.9441624365482233 Was the accuracy when the train data size was 230\n",
            "Train data size:  235\n",
            "Epoch 1/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.6374\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.5619\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.4961\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.4387\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.3882\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.3453\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.3086\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2762\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2522\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2318\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2118\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1978\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1875\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1770\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1684\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1611\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1559\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1498\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1461\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1377\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1383\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1328\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1315\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1278\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1260\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1254\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1213\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1203\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1191\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1176\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1180\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1155\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1136\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1123\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1099\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0969\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1162\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1072\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1077\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1062\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1054\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1015\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1037\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1025\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0989\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0975\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0970\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0987\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0962\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0956\n",
            "0.93 Was the accuracy when the train data size was 235\n",
            "Train data size:  240\n",
            "Epoch 1/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.6190\n",
            "Epoch 2/50\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5484\n",
            "Epoch 3/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.4816\n",
            "Epoch 4/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.4305\n",
            "Epoch 5/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.3786\n",
            "Epoch 6/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.3345\n",
            "Epoch 7/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.2983\n",
            "Epoch 8/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.2678\n",
            "Epoch 9/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.2415\n",
            "Epoch 10/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.2220\n",
            "Epoch 11/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.2039\n",
            "Epoch 12/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1903\n",
            "Epoch 13/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1777\n",
            "Epoch 14/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1697\n",
            "Epoch 15/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1596\n",
            "Epoch 16/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1583\n",
            "Epoch 17/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1479\n",
            "Epoch 18/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1450\n",
            "Epoch 19/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1408\n",
            "Epoch 20/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1379\n",
            "Epoch 21/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1302\n",
            "Epoch 22/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1292\n",
            "Epoch 23/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1281\n",
            "Epoch 24/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1244\n",
            "Epoch 25/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1250\n",
            "Epoch 26/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1195\n",
            "Epoch 27/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1176\n",
            "Epoch 28/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1149\n",
            "Epoch 29/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1186\n",
            "Epoch 30/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1160\n",
            "Epoch 31/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1140\n",
            "Epoch 32/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1115\n",
            "Epoch 33/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1094\n",
            "Epoch 34/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1114\n",
            "Epoch 35/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1067\n",
            "Epoch 36/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1123\n",
            "Epoch 37/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1065\n",
            "Epoch 38/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1057\n",
            "Epoch 39/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1027\n",
            "Epoch 40/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1053\n",
            "Epoch 41/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1004\n",
            "Epoch 42/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1039\n",
            "Epoch 43/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.0989\n",
            "Epoch 44/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.1027\n",
            "Epoch 45/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.0988\n",
            "Epoch 46/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.0988\n",
            "Epoch 47/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.0975\n",
            "Epoch 48/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.0980\n",
            "Epoch 49/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.0968\n",
            "Epoch 50/50\n",
            "240/240 [==============================] - 1s 4ms/step - loss: 0.0946\n",
            "0.93 Was the accuracy when the train data size was 240\n",
            "Train data size:  245\n",
            "Epoch 1/50\n",
            "245/245 [==============================] - 2s 4ms/step - loss: 0.6486\n",
            "Epoch 2/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.5584\n",
            "Epoch 3/50\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.4912\n",
            "Epoch 4/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.4280\n",
            "Epoch 5/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3754\n",
            "Epoch 6/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.3305\n",
            "Epoch 7/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2956\n",
            "Epoch 8/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2635\n",
            "Epoch 9/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2389\n",
            "Epoch 10/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2184\n",
            "Epoch 11/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.2016\n",
            "Epoch 12/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1874\n",
            "Epoch 13/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1740\n",
            "Epoch 14/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1683\n",
            "Epoch 15/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1593\n",
            "Epoch 16/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1496\n",
            "Epoch 17/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1497\n",
            "Epoch 18/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1422\n",
            "Epoch 19/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1379\n",
            "Epoch 20/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1374\n",
            "Epoch 21/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1327\n",
            "Epoch 22/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1289\n",
            "Epoch 23/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1283\n",
            "Epoch 24/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1241\n",
            "Epoch 25/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1224\n",
            "Epoch 26/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1193\n",
            "Epoch 27/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1169\n",
            "Epoch 28/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1162\n",
            "Epoch 29/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1139\n",
            "Epoch 30/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1159\n",
            "Epoch 31/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1151\n",
            "Epoch 32/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1108\n",
            "Epoch 33/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1103\n",
            "Epoch 34/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1078\n",
            "Epoch 35/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1055\n",
            "Epoch 36/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1061\n",
            "Epoch 37/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1028\n",
            "Epoch 38/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1031\n",
            "Epoch 39/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1052\n",
            "Epoch 40/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1019\n",
            "Epoch 41/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1003\n",
            "Epoch 42/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1010\n",
            "Epoch 43/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0991\n",
            "Epoch 44/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.1001\n",
            "Epoch 45/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0984\n",
            "Epoch 46/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0962\n",
            "Epoch 47/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0929\n",
            "Epoch 48/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0954\n",
            "Epoch 49/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0948\n",
            "Epoch 50/50\n",
            "245/245 [==============================] - 1s 4ms/step - loss: 0.0940\n",
            "0.9393939393939394 Was the accuracy when the train data size was 245\n",
            "Train data size:  250\n",
            "Epoch 1/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6955\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5844\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5180\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4564\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4018\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3558\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3161\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.2848\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.2562\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.2344\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.2147\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.2001\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1855\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1773\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1673\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1614\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1504\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1494\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1430\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1408\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1380\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1337\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1310\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1276\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1244\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1189\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1229\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1190\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1172\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1137\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1121\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1152\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1100\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1036\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1106\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1047\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1091\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1051\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1034\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1033\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1026\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.1008\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0997\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0982\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0968\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0956\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0952\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0953\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.0928\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.0933\n",
            "0.93 Was the accuracy when the train data size was 250\n",
            "Train data size:  255\n",
            "Epoch 1/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.5924\n",
            "Epoch 2/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.4863\n",
            "Epoch 3/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.4312\n",
            "Epoch 4/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.3804\n",
            "Epoch 5/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.3328\n",
            "Epoch 6/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.2988\n",
            "Epoch 7/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.2655\n",
            "Epoch 8/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.2397\n",
            "Epoch 9/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.2171\n",
            "Epoch 10/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1967\n",
            "Epoch 11/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1854\n",
            "Epoch 12/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1718\n",
            "Epoch 13/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1622\n",
            "Epoch 14/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1546\n",
            "Epoch 15/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1476\n",
            "Epoch 16/50\n",
            "255/255 [==============================] - 1s 3ms/step - loss: 0.1412\n",
            "Epoch 17/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1349\n",
            "Epoch 18/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1308\n",
            "Epoch 19/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1266\n",
            "Epoch 20/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1239\n",
            "Epoch 21/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1224\n",
            "Epoch 22/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1182\n",
            "Epoch 23/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1159\n",
            "Epoch 24/50\n",
            "255/255 [==============================] - 1s 3ms/step - loss: 0.1136\n",
            "Epoch 25/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1115\n",
            "Epoch 26/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1099\n",
            "Epoch 27/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1097\n",
            "Epoch 28/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1068\n",
            "Epoch 29/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1055\n",
            "Epoch 30/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1040\n",
            "Epoch 31/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1032\n",
            "Epoch 32/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.1004\n",
            "Epoch 33/50\n",
            "255/255 [==============================] - 1s 3ms/step - loss: 0.0995\n",
            "Epoch 34/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0991\n",
            "Epoch 35/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0960\n",
            "Epoch 36/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0975\n",
            "Epoch 37/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0957\n",
            "Epoch 38/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0964\n",
            "Epoch 39/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0952\n",
            "Epoch 40/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0940\n",
            "Epoch 41/50\n",
            "255/255 [==============================] - 1s 3ms/step - loss: 0.0937\n",
            "Epoch 42/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0912\n",
            "Epoch 43/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0908\n",
            "Epoch 44/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0899\n",
            "Epoch 45/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0893\n",
            "Epoch 46/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0897\n",
            "Epoch 47/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0881\n",
            "Epoch 48/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0865\n",
            "Epoch 49/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0866\n",
            "Epoch 50/50\n",
            "255/255 [==============================] - 1s 4ms/step - loss: 0.0859\n",
            "0.9393939393939394 Was the accuracy when the train data size was 255\n",
            "Train data size:  260\n",
            "Epoch 1/50\n",
            "260/260 [==============================] - 2s 4ms/step - loss: 0.6449\n",
            "Epoch 2/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.5649\n",
            "Epoch 3/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.5006\n",
            "Epoch 4/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.4365\n",
            "Epoch 5/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.3903\n",
            "Epoch 6/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.3413\n",
            "Epoch 7/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.3031\n",
            "Epoch 8/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.2696\n",
            "Epoch 9/50\n",
            "260/260 [==============================] - 1s 3ms/step - loss: 0.2425\n",
            "Epoch 10/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.2216\n",
            "Epoch 11/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.2047\n",
            "Epoch 12/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1887\n",
            "Epoch 13/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1783\n",
            "Epoch 14/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1660\n",
            "Epoch 15/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1588\n",
            "Epoch 16/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1530\n",
            "Epoch 17/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1475\n",
            "Epoch 18/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1423\n",
            "Epoch 19/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1365\n",
            "Epoch 20/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1363\n",
            "Epoch 21/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1325\n",
            "Epoch 22/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1295\n",
            "Epoch 23/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1232\n",
            "Epoch 24/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1247\n",
            "Epoch 25/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1215\n",
            "Epoch 26/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1183\n",
            "Epoch 27/50\n",
            "260/260 [==============================] - 1s 3ms/step - loss: 0.1182\n",
            "Epoch 28/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1145\n",
            "Epoch 29/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1120\n",
            "Epoch 30/50\n",
            "260/260 [==============================] - 1s 3ms/step - loss: 0.1114\n",
            "Epoch 31/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1100\n",
            "Epoch 32/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1078\n",
            "Epoch 33/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1074\n",
            "Epoch 34/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1040\n",
            "Epoch 35/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1048\n",
            "Epoch 36/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1014\n",
            "Epoch 37/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.1021\n",
            "Epoch 38/50\n",
            "260/260 [==============================] - 1s 3ms/step - loss: 0.1001\n",
            "Epoch 39/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.0989\n",
            "Epoch 40/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.0968\n",
            "Epoch 41/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.0961\n",
            "Epoch 42/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.0930\n",
            "Epoch 43/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.0931\n",
            "Epoch 44/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.0912\n",
            "Epoch 45/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.0933\n",
            "Epoch 46/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.0921\n",
            "Epoch 47/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.0919\n",
            "Epoch 48/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.0915\n",
            "Epoch 49/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.0898\n",
            "Epoch 50/50\n",
            "260/260 [==============================] - 1s 4ms/step - loss: 0.0893\n",
            "0.9538461538461538 Was the accuracy when the train data size was 260\n",
            "Train data size:  265\n",
            "Epoch 1/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.6157\n",
            "Epoch 2/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.5397\n",
            "Epoch 3/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.4739\n",
            "Epoch 4/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.4127\n",
            "Epoch 5/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.3687\n",
            "Epoch 6/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.3230\n",
            "Epoch 7/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.2867\n",
            "Epoch 8/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.2575\n",
            "Epoch 9/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.2319\n",
            "Epoch 10/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.2129\n",
            "Epoch 11/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1977\n",
            "Epoch 12/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1842\n",
            "Epoch 13/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1739\n",
            "Epoch 14/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1646\n",
            "Epoch 15/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1581\n",
            "Epoch 16/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1540\n",
            "Epoch 17/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1487\n",
            "Epoch 18/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1426\n",
            "Epoch 19/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1372\n",
            "Epoch 20/50\n",
            "265/265 [==============================] - 1s 3ms/step - loss: 0.1354\n",
            "Epoch 21/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1317\n",
            "Epoch 22/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1286\n",
            "Epoch 23/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1251\n",
            "Epoch 24/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1225\n",
            "Epoch 25/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1214\n",
            "Epoch 26/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1203\n",
            "Epoch 27/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1173\n",
            "Epoch 28/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1158\n",
            "Epoch 29/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1113\n",
            "Epoch 30/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1146\n",
            "Epoch 31/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1115\n",
            "Epoch 32/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1097\n",
            "Epoch 33/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1065\n",
            "Epoch 34/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1096\n",
            "Epoch 35/50\n",
            "265/265 [==============================] - 1s 3ms/step - loss: 0.1051\n",
            "Epoch 36/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1056\n",
            "Epoch 37/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1046\n",
            "Epoch 38/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.0993\n",
            "Epoch 39/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1001\n",
            "Epoch 40/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.1010\n",
            "Epoch 41/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.0998\n",
            "Epoch 42/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.0980\n",
            "Epoch 43/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.0969\n",
            "Epoch 44/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.0975\n",
            "Epoch 45/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.0943\n",
            "Epoch 46/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.0928\n",
            "Epoch 47/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.0927\n",
            "Epoch 48/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.0916\n",
            "Epoch 49/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.0892\n",
            "Epoch 50/50\n",
            "265/265 [==============================] - 1s 4ms/step - loss: 0.0891\n",
            "0.9253731343283582 Was the accuracy when the train data size was 265\n",
            "Train data size:  270\n",
            "Epoch 1/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.5988\n",
            "Epoch 2/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.5174\n",
            "Epoch 3/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.4503\n",
            "Epoch 4/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.3939\n",
            "Epoch 5/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.3455\n",
            "Epoch 6/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.3051\n",
            "Epoch 7/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.2692\n",
            "Epoch 8/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.2447\n",
            "Epoch 9/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.2221\n",
            "Epoch 10/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.2055\n",
            "Epoch 11/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1891\n",
            "Epoch 12/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1776\n",
            "Epoch 13/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1668\n",
            "Epoch 14/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1583\n",
            "Epoch 15/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1526\n",
            "Epoch 16/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1463\n",
            "Epoch 17/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1411\n",
            "Epoch 18/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1390\n",
            "Epoch 19/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1347\n",
            "Epoch 20/50\n",
            "270/270 [==============================] - 1s 3ms/step - loss: 0.1306\n",
            "Epoch 21/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1286\n",
            "Epoch 22/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1267\n",
            "Epoch 23/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1240\n",
            "Epoch 24/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1232\n",
            "Epoch 25/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1208\n",
            "Epoch 26/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1179\n",
            "Epoch 27/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1146\n",
            "Epoch 28/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1129\n",
            "Epoch 29/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1118\n",
            "Epoch 30/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1070\n",
            "Epoch 31/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1116\n",
            "Epoch 32/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1099\n",
            "Epoch 33/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1036\n",
            "Epoch 34/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1058\n",
            "Epoch 35/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1033\n",
            "Epoch 36/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0991\n",
            "Epoch 37/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1050\n",
            "Epoch 38/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.1029\n",
            "Epoch 39/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0999\n",
            "Epoch 40/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0995\n",
            "Epoch 41/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0956\n",
            "Epoch 42/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0967\n",
            "Epoch 43/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0937\n",
            "Epoch 44/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0934\n",
            "Epoch 45/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0942\n",
            "Epoch 46/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0919\n",
            "Epoch 47/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0888\n",
            "Epoch 48/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0889\n",
            "Epoch 49/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0887\n",
            "Epoch 50/50\n",
            "270/270 [==============================] - 1s 4ms/step - loss: 0.0874\n",
            "0.9346733668341708 Was the accuracy when the train data size was 270\n",
            "Train data size:  275\n",
            "Epoch 1/50\n",
            "275/275 [==============================] - 2s 4ms/step - loss: 0.6484\n",
            "Epoch 2/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.5589\n",
            "Epoch 3/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.4862\n",
            "Epoch 4/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.4238\n",
            "Epoch 5/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.3726\n",
            "Epoch 6/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.3299\n",
            "Epoch 7/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.2935\n",
            "Epoch 8/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.2639\n",
            "Epoch 9/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.2398\n",
            "Epoch 10/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.2161\n",
            "Epoch 11/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.2046\n",
            "Epoch 12/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1886\n",
            "Epoch 13/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1824\n",
            "Epoch 14/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1712\n",
            "Epoch 15/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1659\n",
            "Epoch 16/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1564\n",
            "Epoch 17/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1545\n",
            "Epoch 18/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1496\n",
            "Epoch 19/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1454\n",
            "Epoch 20/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1394\n",
            "Epoch 21/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1389\n",
            "Epoch 22/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1341\n",
            "Epoch 23/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1345\n",
            "Epoch 24/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1309\n",
            "Epoch 25/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1252\n",
            "Epoch 26/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1281\n",
            "Epoch 27/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1223\n",
            "Epoch 28/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1216\n",
            "Epoch 29/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1177\n",
            "Epoch 30/50\n",
            "275/275 [==============================] - 1s 3ms/step - loss: 0.1191\n",
            "Epoch 31/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1156\n",
            "Epoch 32/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1151\n",
            "Epoch 33/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1132\n",
            "Epoch 34/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1117\n",
            "Epoch 35/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1098\n",
            "Epoch 36/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1089\n",
            "Epoch 37/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1075\n",
            "Epoch 38/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1061\n",
            "Epoch 39/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1033\n",
            "Epoch 40/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1027\n",
            "Epoch 41/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1016\n",
            "Epoch 42/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1009\n",
            "Epoch 43/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.1021\n",
            "Epoch 44/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.0996\n",
            "Epoch 45/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.0969\n",
            "Epoch 46/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.0954\n",
            "Epoch 47/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.0945\n",
            "Epoch 48/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.0957\n",
            "Epoch 49/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.0961\n",
            "Epoch 50/50\n",
            "275/275 [==============================] - 1s 4ms/step - loss: 0.0950\n",
            "0.9253731343283582 Was the accuracy when the train data size was 275\n",
            "Train data size:  280\n",
            "Epoch 1/50\n",
            "280/280 [==============================] - 2s 4ms/step - loss: 0.6766\n",
            "Epoch 2/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.5850\n",
            "Epoch 3/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.5078\n",
            "Epoch 4/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.4403\n",
            "Epoch 5/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.3794\n",
            "Epoch 6/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.3281\n",
            "Epoch 7/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.2858\n",
            "Epoch 8/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.2529\n",
            "Epoch 9/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.2307\n",
            "Epoch 10/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.2078\n",
            "Epoch 11/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1898\n",
            "Epoch 12/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1797\n",
            "Epoch 13/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1662\n",
            "Epoch 14/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1603\n",
            "Epoch 15/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1498\n",
            "Epoch 16/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1474\n",
            "Epoch 17/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1414\n",
            "Epoch 18/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1354\n",
            "Epoch 19/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1319\n",
            "Epoch 20/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1292\n",
            "Epoch 21/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1247\n",
            "Epoch 22/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1155\n",
            "Epoch 23/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1212\n",
            "Epoch 24/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1167\n",
            "Epoch 25/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1139\n",
            "Epoch 26/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1132\n",
            "Epoch 27/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1106\n",
            "Epoch 28/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1077\n",
            "Epoch 29/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1082\n",
            "Epoch 30/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1081\n",
            "Epoch 31/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1066\n",
            "Epoch 32/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1027\n",
            "Epoch 33/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0983\n",
            "Epoch 34/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0999\n",
            "Epoch 35/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0982\n",
            "Epoch 36/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0985\n",
            "Epoch 37/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0927\n",
            "Epoch 38/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0961\n",
            "Epoch 39/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0926\n",
            "Epoch 40/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0958\n",
            "Epoch 41/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0952\n",
            "Epoch 42/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0913\n",
            "Epoch 43/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0911\n",
            "Epoch 44/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0898\n",
            "Epoch 45/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0886\n",
            "Epoch 46/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0873\n",
            "Epoch 47/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0885\n",
            "Epoch 48/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0870\n",
            "Epoch 49/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0821\n",
            "Epoch 50/50\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0827\n",
            "0.9393939393939394 Was the accuracy when the train data size was 280\n",
            "Train data size:  285\n",
            "Epoch 1/50\n",
            "285/285 [==============================] - 2s 4ms/step - loss: 0.6155\n",
            "Epoch 2/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.5317\n",
            "Epoch 3/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.4571\n",
            "Epoch 4/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.3949\n",
            "Epoch 5/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.3408\n",
            "Epoch 6/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.2959\n",
            "Epoch 7/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.2591\n",
            "Epoch 8/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.2306\n",
            "Epoch 9/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.2091\n",
            "Epoch 10/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1940\n",
            "Epoch 11/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1772\n",
            "Epoch 12/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1689\n",
            "Epoch 13/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1579\n",
            "Epoch 14/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1505\n",
            "Epoch 15/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1439\n",
            "Epoch 16/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1371\n",
            "Epoch 17/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1322\n",
            "Epoch 18/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1297\n",
            "Epoch 19/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1247\n",
            "Epoch 20/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1213\n",
            "Epoch 21/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1197\n",
            "Epoch 22/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1167\n",
            "Epoch 23/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1113\n",
            "Epoch 24/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1120\n",
            "Epoch 25/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1105\n",
            "Epoch 26/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1086\n",
            "Epoch 27/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1042\n",
            "Epoch 28/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1014\n",
            "Epoch 29/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1009\n",
            "Epoch 30/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.1014\n",
            "Epoch 31/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0999\n",
            "Epoch 32/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0982\n",
            "Epoch 33/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0940\n",
            "Epoch 34/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0957\n",
            "Epoch 35/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0918\n",
            "Epoch 36/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 37/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0917\n",
            "Epoch 38/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0846\n",
            "Epoch 39/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0911\n",
            "Epoch 40/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0897\n",
            "Epoch 41/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0865\n",
            "Epoch 42/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0856\n",
            "Epoch 43/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0876\n",
            "Epoch 44/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0847\n",
            "Epoch 45/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0833\n",
            "Epoch 46/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0841\n",
            "Epoch 47/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0823\n",
            "Epoch 48/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0786\n",
            "Epoch 49/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0822\n",
            "Epoch 50/50\n",
            "285/285 [==============================] - 1s 4ms/step - loss: 0.0777\n",
            "0.9253731343283582 Was the accuracy when the train data size was 285\n",
            "Train data size:  290\n",
            "Epoch 1/50\n",
            "290/290 [==============================] - 2s 4ms/step - loss: 0.6724\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.5819\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.5084\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.4427\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3864\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.3375\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2942\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2583\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2349\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.2127\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1954\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1819\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1714\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1635\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1520\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1512\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1449\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1407\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1376\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1335\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1306\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1261\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1257\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1218\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1201\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1175\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1130\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1147\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1136\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1096\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1068\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1086\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1065\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1032\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1032\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.0998\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.1019\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.0970\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.0965\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.0978\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.0939\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.0943\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.0913\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.0920\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.0854\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.0914\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.0888\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.0878\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.0856\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 1s 4ms/step - loss: 0.0854\n",
            "0.9441624365482233 Was the accuracy when the train data size was 290\n",
            "Train data size:  295\n",
            "Epoch 1/50\n",
            "295/295 [==============================] - 2s 4ms/step - loss: 0.5993\n",
            "Epoch 2/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.5066\n",
            "Epoch 3/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.4322\n",
            "Epoch 4/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.3723\n",
            "Epoch 5/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.3225\n",
            "Epoch 6/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.2825\n",
            "Epoch 7/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.2513\n",
            "Epoch 8/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.2250\n",
            "Epoch 9/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.2060\n",
            "Epoch 10/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1903\n",
            "Epoch 11/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1782\n",
            "Epoch 12/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1669\n",
            "Epoch 13/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1576\n",
            "Epoch 14/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1555\n",
            "Epoch 15/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1441\n",
            "Epoch 16/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1444\n",
            "Epoch 17/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1383\n",
            "Epoch 18/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1332\n",
            "Epoch 19/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1312\n",
            "Epoch 20/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1267\n",
            "Epoch 21/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1261\n",
            "Epoch 22/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1232\n",
            "Epoch 23/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1231\n",
            "Epoch 24/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1180\n",
            "Epoch 25/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1166\n",
            "Epoch 26/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1161\n",
            "Epoch 27/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1149\n",
            "Epoch 28/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1087\n",
            "Epoch 29/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1116\n",
            "Epoch 30/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1075\n",
            "Epoch 31/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1019\n",
            "Epoch 32/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1061\n",
            "Epoch 33/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1024\n",
            "Epoch 34/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1014\n",
            "Epoch 35/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.0981\n",
            "Epoch 36/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.1005\n",
            "Epoch 37/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.0978\n",
            "Epoch 38/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.0986\n",
            "Epoch 39/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.0959\n",
            "Epoch 40/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.0949\n",
            "Epoch 41/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.0943\n",
            "Epoch 42/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.0935\n",
            "Epoch 43/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.0859\n",
            "Epoch 44/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 45/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.0892\n",
            "Epoch 46/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.0872\n",
            "Epoch 47/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.0860\n",
            "Epoch 48/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.0837\n",
            "Epoch 49/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.0869\n",
            "Epoch 50/50\n",
            "295/295 [==============================] - 1s 4ms/step - loss: 0.0887\n",
            "0.9346733668341708 Was the accuracy when the train data size was 295\n",
            "Train data size:  300\n",
            "Epoch 1/50\n",
            "300/300 [==============================] - 2s 4ms/step - loss: 0.6169\n",
            "Epoch 2/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.5261\n",
            "Epoch 3/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.4550\n",
            "Epoch 4/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3895\n",
            "Epoch 5/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.3353\n",
            "Epoch 6/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.2919\n",
            "Epoch 7/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.2559\n",
            "Epoch 8/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.2271\n",
            "Epoch 9/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.2059\n",
            "Epoch 10/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1899\n",
            "Epoch 11/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1752\n",
            "Epoch 12/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1648\n",
            "Epoch 13/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1563\n",
            "Epoch 14/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1488\n",
            "Epoch 15/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1400\n",
            "Epoch 16/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1404\n",
            "Epoch 17/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1335\n",
            "Epoch 18/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1315\n",
            "Epoch 19/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1259\n",
            "Epoch 20/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1236\n",
            "Epoch 21/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1198\n",
            "Epoch 22/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1195\n",
            "Epoch 23/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1169\n",
            "Epoch 24/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1144\n",
            "Epoch 25/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1123\n",
            "Epoch 26/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1109\n",
            "Epoch 27/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1137\n",
            "Epoch 28/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1063\n",
            "Epoch 29/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1061\n",
            "Epoch 30/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1047\n",
            "Epoch 31/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1039\n",
            "Epoch 32/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1018\n",
            "Epoch 33/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.1006\n",
            "Epoch 34/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0988\n",
            "Epoch 35/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0973\n",
            "Epoch 36/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0977\n",
            "Epoch 37/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0961\n",
            "Epoch 38/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0956\n",
            "Epoch 39/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0926\n",
            "Epoch 40/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0904\n",
            "Epoch 41/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0931\n",
            "Epoch 42/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0896\n",
            "Epoch 43/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0898\n",
            "Epoch 44/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0871\n",
            "Epoch 45/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0889\n",
            "Epoch 46/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0882\n",
            "Epoch 47/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0850\n",
            "Epoch 48/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0847\n",
            "Epoch 49/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0841\n",
            "Epoch 50/50\n",
            "300/300 [==============================] - 1s 4ms/step - loss: 0.0818\n",
            "0.9538461538461538 Was the accuracy when the train data size was 300\n",
            "Train data size:  305\n",
            "Epoch 1/50\n",
            "305/305 [==============================] - 2s 4ms/step - loss: 0.5789\n",
            "Epoch 2/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.5042\n",
            "Epoch 3/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.4358\n",
            "Epoch 4/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.3779\n",
            "Epoch 5/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.3279\n",
            "Epoch 6/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.2863\n",
            "Epoch 7/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.2513\n",
            "Epoch 8/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.2278\n",
            "Epoch 9/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.2061\n",
            "Epoch 10/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1897\n",
            "Epoch 11/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1778\n",
            "Epoch 12/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1651\n",
            "Epoch 13/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1595\n",
            "Epoch 14/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1510\n",
            "Epoch 15/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1451\n",
            "Epoch 16/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1422\n",
            "Epoch 17/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1356\n",
            "Epoch 18/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1321\n",
            "Epoch 19/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1297\n",
            "Epoch 20/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1256\n",
            "Epoch 21/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1215\n",
            "Epoch 22/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1194\n",
            "Epoch 23/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1181\n",
            "Epoch 24/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1151\n",
            "Epoch 25/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1137\n",
            "Epoch 26/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1127\n",
            "Epoch 27/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1099\n",
            "Epoch 28/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1078\n",
            "Epoch 29/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1070\n",
            "Epoch 30/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1063\n",
            "Epoch 31/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1016\n",
            "Epoch 32/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0999\n",
            "Epoch 33/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1017\n",
            "Epoch 34/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.1003\n",
            "Epoch 35/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0966\n",
            "Epoch 36/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0963\n",
            "Epoch 37/50\n",
            "305/305 [==============================] - 1s 3ms/step - loss: 0.0972\n",
            "Epoch 38/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0921\n",
            "Epoch 39/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0941\n",
            "Epoch 40/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0933\n",
            "Epoch 41/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0920\n",
            "Epoch 42/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0907\n",
            "Epoch 43/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0923\n",
            "Epoch 44/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0867\n",
            "Epoch 45/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0876\n",
            "Epoch 46/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0869\n",
            "Epoch 47/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0871\n",
            "Epoch 48/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0839\n",
            "Epoch 49/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0863\n",
            "Epoch 50/50\n",
            "305/305 [==============================] - 1s 4ms/step - loss: 0.0838\n",
            "0.9538461538461538 Was the accuracy when the train data size was 305\n",
            "Train data size:  310\n",
            "Epoch 1/50\n",
            "310/310 [==============================] - 2s 4ms/step - loss: 0.6079\n",
            "Epoch 2/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.5201\n",
            "Epoch 3/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.4476\n",
            "Epoch 4/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.3869\n",
            "Epoch 5/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.3343\n",
            "Epoch 6/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.2916\n",
            "Epoch 7/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.2548\n",
            "Epoch 8/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.2266\n",
            "Epoch 9/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.2039\n",
            "Epoch 10/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1905\n",
            "Epoch 11/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1771\n",
            "Epoch 12/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1640\n",
            "Epoch 13/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1557\n",
            "Epoch 14/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1496\n",
            "Epoch 15/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1447\n",
            "Epoch 16/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1389\n",
            "Epoch 17/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1343\n",
            "Epoch 18/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1291\n",
            "Epoch 19/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1259\n",
            "Epoch 20/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1222\n",
            "Epoch 21/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1189\n",
            "Epoch 22/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1177\n",
            "Epoch 23/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1138\n",
            "Epoch 24/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1076\n",
            "Epoch 25/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1115\n",
            "Epoch 26/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1107\n",
            "Epoch 27/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1076\n",
            "Epoch 28/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1041\n",
            "Epoch 29/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1025\n",
            "Epoch 30/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1013\n",
            "Epoch 31/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.1000\n",
            "Epoch 32/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0993\n",
            "Epoch 33/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0953\n",
            "Epoch 34/50\n",
            "310/310 [==============================] - 1s 3ms/step - loss: 0.0961\n",
            "Epoch 35/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0948\n",
            "Epoch 36/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0919\n",
            "Epoch 37/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0887\n",
            "Epoch 38/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0887\n",
            "Epoch 39/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0877\n",
            "Epoch 40/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0882\n",
            "Epoch 41/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0865\n",
            "Epoch 42/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0857\n",
            "Epoch 43/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0833\n",
            "Epoch 44/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0850\n",
            "Epoch 45/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0815\n",
            "Epoch 46/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0822\n",
            "Epoch 47/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0827\n",
            "Epoch 48/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0782\n",
            "Epoch 49/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0793\n",
            "Epoch 50/50\n",
            "310/310 [==============================] - 1s 4ms/step - loss: 0.0768\n",
            "0.9587628865979382 Was the accuracy when the train data size was 310\n",
            "Train data size:  315\n",
            "Epoch 1/50\n",
            "315/315 [==============================] - 2s 4ms/step - loss: 0.6093\n",
            "Epoch 2/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.5328\n",
            "Epoch 3/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.4607\n",
            "Epoch 4/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.3991\n",
            "Epoch 5/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.3422\n",
            "Epoch 6/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.2951\n",
            "Epoch 7/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.2593\n",
            "Epoch 8/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.2285\n",
            "Epoch 9/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.2066\n",
            "Epoch 10/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1893\n",
            "Epoch 11/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1766\n",
            "Epoch 12/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1650\n",
            "Epoch 13/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1594\n",
            "Epoch 14/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1506\n",
            "Epoch 15/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1416\n",
            "Epoch 16/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1394\n",
            "Epoch 17/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1355\n",
            "Epoch 18/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1299\n",
            "Epoch 19/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1279\n",
            "Epoch 20/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1252\n",
            "Epoch 21/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1204\n",
            "Epoch 22/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1202\n",
            "Epoch 23/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1166\n",
            "Epoch 24/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1151\n",
            "Epoch 25/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1098\n",
            "Epoch 26/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1114\n",
            "Epoch 27/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1090\n",
            "Epoch 28/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1061\n",
            "Epoch 29/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1065\n",
            "Epoch 30/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1010\n",
            "Epoch 31/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1036\n",
            "Epoch 32/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1003\n",
            "Epoch 33/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.1014\n",
            "Epoch 34/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0986\n",
            "Epoch 35/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0963\n",
            "Epoch 36/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0948\n",
            "Epoch 37/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0945\n",
            "Epoch 38/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0919\n",
            "Epoch 39/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0914\n",
            "Epoch 40/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0917\n",
            "Epoch 41/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0908\n",
            "Epoch 42/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0867\n",
            "Epoch 43/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0879\n",
            "Epoch 44/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0851\n",
            "Epoch 45/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0891\n",
            "Epoch 46/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0858\n",
            "Epoch 47/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0850\n",
            "Epoch 48/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0836\n",
            "Epoch 49/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0831\n",
            "Epoch 50/50\n",
            "315/315 [==============================] - 1s 4ms/step - loss: 0.0801\n",
            "0.9207920792079208 Was the accuracy when the train data size was 315\n",
            "Train data size:  320\n",
            "Epoch 1/50\n",
            "320/320 [==============================] - 2s 4ms/step - loss: 0.6265\n",
            "Epoch 2/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.5303\n",
            "Epoch 3/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.4587\n",
            "Epoch 4/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.3877\n",
            "Epoch 5/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.3357\n",
            "Epoch 6/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.2889\n",
            "Epoch 7/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.2548\n",
            "Epoch 8/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.2272\n",
            "Epoch 9/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.2077\n",
            "Epoch 10/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1902\n",
            "Epoch 11/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1783\n",
            "Epoch 12/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1680\n",
            "Epoch 13/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1582\n",
            "Epoch 14/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1516\n",
            "Epoch 15/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1481\n",
            "Epoch 16/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1428\n",
            "Epoch 17/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1378\n",
            "Epoch 18/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1337\n",
            "Epoch 19/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1300\n",
            "Epoch 20/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1252\n",
            "Epoch 21/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1239\n",
            "Epoch 22/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1208\n",
            "Epoch 23/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1182\n",
            "Epoch 24/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1167\n",
            "Epoch 25/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1131\n",
            "Epoch 26/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1099\n",
            "Epoch 27/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1123\n",
            "Epoch 28/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1071\n",
            "Epoch 29/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1065\n",
            "Epoch 30/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1052\n",
            "Epoch 31/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1025\n",
            "Epoch 32/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1034\n",
            "Epoch 33/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.1004\n",
            "Epoch 34/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0991\n",
            "Epoch 35/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0980\n",
            "Epoch 36/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0965\n",
            "Epoch 37/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0938\n",
            "Epoch 38/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0966\n",
            "Epoch 39/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0934\n",
            "Epoch 40/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0918\n",
            "Epoch 41/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0918\n",
            "Epoch 42/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0899\n",
            "Epoch 43/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0906\n",
            "Epoch 44/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0866\n",
            "Epoch 45/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0898\n",
            "Epoch 46/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0859\n",
            "Epoch 47/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0842\n",
            "Epoch 48/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0845\n",
            "Epoch 49/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0828\n",
            "Epoch 50/50\n",
            "320/320 [==============================] - 1s 4ms/step - loss: 0.0802\n",
            "0.9538461538461538 Was the accuracy when the train data size was 320\n",
            "Train data size:  325\n",
            "Epoch 1/50\n",
            "325/325 [==============================] - 2s 4ms/step - loss: 0.6711\n",
            "Epoch 2/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.5868\n",
            "Epoch 3/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.5116\n",
            "Epoch 4/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.4408\n",
            "Epoch 5/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.3775\n",
            "Epoch 6/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.3253\n",
            "Epoch 7/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.2814\n",
            "Epoch 8/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.2480\n",
            "Epoch 9/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.2197\n",
            "Epoch 10/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.2008\n",
            "Epoch 11/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1861\n",
            "Epoch 12/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1713\n",
            "Epoch 13/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1625\n",
            "Epoch 14/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1533\n",
            "Epoch 15/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1472\n",
            "Epoch 16/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1379\n",
            "Epoch 17/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1385\n",
            "Epoch 18/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1323\n",
            "Epoch 19/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1288\n",
            "Epoch 20/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1241\n",
            "Epoch 21/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1231\n",
            "Epoch 22/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1177\n",
            "Epoch 23/50\n",
            "325/325 [==============================] - 1s 3ms/step - loss: 0.1169\n",
            "Epoch 24/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1157\n",
            "Epoch 25/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1144\n",
            "Epoch 26/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1132\n",
            "Epoch 27/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1081\n",
            "Epoch 28/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1071\n",
            "Epoch 29/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1048\n",
            "Epoch 30/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1041\n",
            "Epoch 31/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1039\n",
            "Epoch 32/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1003\n",
            "Epoch 33/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1014\n",
            "Epoch 34/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.1006\n",
            "Epoch 35/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0974\n",
            "Epoch 36/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0961\n",
            "Epoch 37/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0951\n",
            "Epoch 38/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0946\n",
            "Epoch 39/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0918\n",
            "Epoch 40/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0909\n",
            "Epoch 41/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0904\n",
            "Epoch 42/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0884\n",
            "Epoch 43/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0869\n",
            "Epoch 44/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0877\n",
            "Epoch 45/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0861\n",
            "Epoch 46/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0831\n",
            "Epoch 47/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0823\n",
            "Epoch 48/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0817\n",
            "Epoch 49/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0819\n",
            "Epoch 50/50\n",
            "325/325 [==============================] - 1s 4ms/step - loss: 0.0796\n",
            "0.9346733668341708 Was the accuracy when the train data size was 325\n",
            "Train data size:  330\n",
            "Epoch 1/50\n",
            "330/330 [==============================] - 2s 4ms/step - loss: 0.6362\n",
            "Epoch 2/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.5400\n",
            "Epoch 3/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.4613\n",
            "Epoch 4/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.3947\n",
            "Epoch 5/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.3369\n",
            "Epoch 6/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.2919\n",
            "Epoch 7/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.2572\n",
            "Epoch 8/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.2260\n",
            "Epoch 9/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.2084\n",
            "Epoch 10/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1934\n",
            "Epoch 11/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1801\n",
            "Epoch 12/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1685\n",
            "Epoch 13/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1597\n",
            "Epoch 14/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1528\n",
            "Epoch 15/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1462\n",
            "Epoch 16/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1441\n",
            "Epoch 17/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1382\n",
            "Epoch 18/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1340\n",
            "Epoch 19/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1308\n",
            "Epoch 20/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1284\n",
            "Epoch 21/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1249\n",
            "Epoch 22/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1213\n",
            "Epoch 23/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1191\n",
            "Epoch 24/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1166\n",
            "Epoch 25/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1151\n",
            "Epoch 26/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1115\n",
            "Epoch 27/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1125\n",
            "Epoch 28/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1090\n",
            "Epoch 29/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1043\n",
            "Epoch 30/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1044\n",
            "Epoch 31/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1021\n",
            "Epoch 32/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.1008\n",
            "Epoch 33/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0980\n",
            "Epoch 34/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0974\n",
            "Epoch 35/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0967\n",
            "Epoch 36/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0963\n",
            "Epoch 37/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0940\n",
            "Epoch 38/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0931\n",
            "Epoch 39/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0919\n",
            "Epoch 40/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0915\n",
            "Epoch 41/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0886\n",
            "Epoch 42/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0858\n",
            "Epoch 43/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0865\n",
            "Epoch 44/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0862\n",
            "Epoch 45/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0850\n",
            "Epoch 46/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0847\n",
            "Epoch 47/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0792\n",
            "Epoch 48/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0804\n",
            "Epoch 49/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0800\n",
            "Epoch 50/50\n",
            "330/330 [==============================] - 1s 4ms/step - loss: 0.0786\n",
            "0.9441624365482233 Was the accuracy when the train data size was 330\n",
            "Train data size:  335\n",
            "Epoch 1/50\n",
            "335/335 [==============================] - 2s 4ms/step - loss: 0.6115\n",
            "Epoch 2/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.5230\n",
            "Epoch 3/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.4457\n",
            "Epoch 4/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.3827\n",
            "Epoch 5/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.3268\n",
            "Epoch 6/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.2861\n",
            "Epoch 7/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.2531\n",
            "Epoch 8/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.2255\n",
            "Epoch 9/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.2053\n",
            "Epoch 10/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1910\n",
            "Epoch 11/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1784\n",
            "Epoch 12/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1683\n",
            "Epoch 13/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1622\n",
            "Epoch 14/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1553\n",
            "Epoch 15/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1478\n",
            "Epoch 16/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1454\n",
            "Epoch 17/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1403\n",
            "Epoch 18/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1364\n",
            "Epoch 19/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1336\n",
            "Epoch 20/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1300\n",
            "Epoch 21/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1269\n",
            "Epoch 22/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1230\n",
            "Epoch 23/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1219\n",
            "Epoch 24/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1202\n",
            "Epoch 25/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1187\n",
            "Epoch 26/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1147\n",
            "Epoch 27/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1132\n",
            "Epoch 28/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1097\n",
            "Epoch 29/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1125\n",
            "Epoch 30/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1043\n",
            "Epoch 31/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1095\n",
            "Epoch 32/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1062\n",
            "Epoch 33/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1045\n",
            "Epoch 34/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1027\n",
            "Epoch 35/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.1021\n",
            "Epoch 36/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.0994\n",
            "Epoch 37/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.0966\n",
            "Epoch 38/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.0974\n",
            "Epoch 39/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.0937\n",
            "Epoch 40/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.0939\n",
            "Epoch 41/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.0951\n",
            "Epoch 42/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.0936\n",
            "Epoch 43/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.0921\n",
            "Epoch 44/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.0910\n",
            "Epoch 45/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.0904\n",
            "Epoch 46/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.0887\n",
            "Epoch 47/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.0881\n",
            "Epoch 48/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.0868\n",
            "Epoch 49/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.0829\n",
            "Epoch 50/50\n",
            "335/335 [==============================] - 1s 4ms/step - loss: 0.0821\n",
            "0.9073170731707317 Was the accuracy when the train data size was 335\n",
            "Train data size:  340\n",
            "Epoch 1/50\n",
            "340/340 [==============================] - 2s 4ms/step - loss: 0.6156\n",
            "Epoch 2/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.5230\n",
            "Epoch 3/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.4370\n",
            "Epoch 4/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.3691\n",
            "Epoch 5/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.3146\n",
            "Epoch 6/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.2718\n",
            "Epoch 7/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.2370\n",
            "Epoch 8/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.2156\n",
            "Epoch 9/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1960\n",
            "Epoch 10/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1821\n",
            "Epoch 11/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1696\n",
            "Epoch 12/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1606\n",
            "Epoch 13/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1541\n",
            "Epoch 14/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1487\n",
            "Epoch 15/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1423\n",
            "Epoch 16/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1411\n",
            "Epoch 17/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1355\n",
            "Epoch 18/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1316\n",
            "Epoch 19/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1331\n",
            "Epoch 20/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1255\n",
            "Epoch 21/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1213\n",
            "Epoch 22/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1208\n",
            "Epoch 23/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1135\n",
            "Epoch 24/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1168\n",
            "Epoch 25/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1152\n",
            "Epoch 26/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1112\n",
            "Epoch 27/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1118\n",
            "Epoch 28/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1050\n",
            "Epoch 29/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1079\n",
            "Epoch 30/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1059\n",
            "Epoch 31/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1031\n",
            "Epoch 32/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1013\n",
            "Epoch 33/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.1018\n",
            "Epoch 34/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.0996\n",
            "Epoch 35/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.0963\n",
            "Epoch 36/50\n",
            "340/340 [==============================] - 1s 3ms/step - loss: 0.0988\n",
            "Epoch 37/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.0948\n",
            "Epoch 38/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.0947\n",
            "Epoch 39/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.0874\n",
            "Epoch 40/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.0949\n",
            "Epoch 41/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.0902\n",
            "Epoch 42/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.0908\n",
            "Epoch 43/50\n",
            "340/340 [==============================] - 1s 3ms/step - loss: 0.0879\n",
            "Epoch 44/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.0844\n",
            "Epoch 45/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.0849\n",
            "Epoch 46/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.0866\n",
            "Epoch 47/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.0845\n",
            "Epoch 48/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.0835\n",
            "Epoch 49/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.0882\n",
            "Epoch 50/50\n",
            "340/340 [==============================] - 1s 4ms/step - loss: 0.0840\n",
            "0.93 Was the accuracy when the train data size was 340\n",
            "Train data size:  345\n",
            "Epoch 1/50\n",
            "345/345 [==============================] - 2s 4ms/step - loss: 0.7386\n",
            "Epoch 2/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.5699\n",
            "Epoch 3/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.4820\n",
            "Epoch 4/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.4087\n",
            "Epoch 5/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.3485\n",
            "Epoch 6/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.2992\n",
            "Epoch 7/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.2607\n",
            "Epoch 8/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.2327\n",
            "Epoch 9/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.2092\n",
            "Epoch 10/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1953\n",
            "Epoch 11/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1801\n",
            "Epoch 12/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1733\n",
            "Epoch 13/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1640\n",
            "Epoch 14/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1563\n",
            "Epoch 15/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1515\n",
            "Epoch 16/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1470\n",
            "Epoch 17/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1410\n",
            "Epoch 18/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1391\n",
            "Epoch 19/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1358\n",
            "Epoch 20/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1313\n",
            "Epoch 21/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1297\n",
            "Epoch 22/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1252\n",
            "Epoch 23/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1241\n",
            "Epoch 24/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1208\n",
            "Epoch 25/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1220\n",
            "Epoch 26/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1178\n",
            "Epoch 27/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1158\n",
            "Epoch 28/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1163\n",
            "Epoch 29/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1140\n",
            "Epoch 30/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1113\n",
            "Epoch 31/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1103\n",
            "Epoch 32/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1080\n",
            "Epoch 33/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1058\n",
            "Epoch 34/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1064\n",
            "Epoch 35/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1053\n",
            "Epoch 36/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1025\n",
            "Epoch 37/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1064\n",
            "Epoch 38/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.1005\n",
            "Epoch 39/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.0972\n",
            "Epoch 40/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.0976\n",
            "Epoch 41/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.0994\n",
            "Epoch 42/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.0966\n",
            "Epoch 43/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.0968\n",
            "Epoch 44/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.0973\n",
            "Epoch 45/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.0933\n",
            "Epoch 46/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.0901\n",
            "Epoch 47/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.0931\n",
            "Epoch 48/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.0911\n",
            "Epoch 49/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.0885\n",
            "Epoch 50/50\n",
            "345/345 [==============================] - 1s 4ms/step - loss: 0.0878\n",
            "0.9207920792079208 Was the accuracy when the train data size was 345\n",
            "Train data size:  350\n",
            "Epoch 1/50\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.6404\n",
            "Epoch 2/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.5464\n",
            "Epoch 3/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.4689\n",
            "Epoch 4/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3964\n",
            "Epoch 5/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.3373\n",
            "Epoch 6/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2901\n",
            "Epoch 7/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2522\n",
            "Epoch 8/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2242\n",
            "Epoch 9/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.2036\n",
            "Epoch 10/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1853\n",
            "Epoch 11/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1731\n",
            "Epoch 12/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1654\n",
            "Epoch 13/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1572\n",
            "Epoch 14/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1501\n",
            "Epoch 15/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1454\n",
            "Epoch 16/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1401\n",
            "Epoch 17/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1384\n",
            "Epoch 18/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1327\n",
            "Epoch 19/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1313\n",
            "Epoch 20/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1306\n",
            "Epoch 21/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1234\n",
            "Epoch 22/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1226\n",
            "Epoch 23/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1205\n",
            "Epoch 24/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1185\n",
            "Epoch 25/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1148\n",
            "Epoch 26/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1150\n",
            "Epoch 27/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1106\n",
            "Epoch 28/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1083\n",
            "Epoch 29/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1093\n",
            "Epoch 30/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1080\n",
            "Epoch 31/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1060\n",
            "Epoch 32/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1038\n",
            "Epoch 33/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1025\n",
            "Epoch 34/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1004\n",
            "Epoch 35/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.1016\n",
            "Epoch 36/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0999\n",
            "Epoch 37/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0971\n",
            "Epoch 38/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0964\n",
            "Epoch 39/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0953\n",
            "Epoch 40/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0946\n",
            "Epoch 41/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0948\n",
            "Epoch 42/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0933\n",
            "Epoch 43/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0892\n",
            "Epoch 44/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0902\n",
            "Epoch 45/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0910\n",
            "Epoch 46/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0918\n",
            "Epoch 47/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0890\n",
            "Epoch 48/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0867\n",
            "Epoch 49/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0902\n",
            "Epoch 50/50\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.0877\n",
            "0.9207920792079208 Was the accuracy when the train data size was 350\n",
            "Train data size:  355\n",
            "Epoch 1/50\n",
            "355/355 [==============================] - 2s 4ms/step - loss: 0.6476\n",
            "Epoch 2/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.5295\n",
            "Epoch 3/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.4408\n",
            "Epoch 4/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.3707\n",
            "Epoch 5/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.3160\n",
            "Epoch 6/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.2749\n",
            "Epoch 7/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.2413\n",
            "Epoch 8/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.2189\n",
            "Epoch 9/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1989\n",
            "Epoch 10/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1847\n",
            "Epoch 11/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1736\n",
            "Epoch 12/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1640\n",
            "Epoch 13/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1595\n",
            "Epoch 14/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1516\n",
            "Epoch 15/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1466\n",
            "Epoch 16/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1421\n",
            "Epoch 17/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1352\n",
            "Epoch 18/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1362\n",
            "Epoch 19/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1327\n",
            "Epoch 20/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1273\n",
            "Epoch 21/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1226\n",
            "Epoch 22/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1244\n",
            "Epoch 23/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1239\n",
            "Epoch 24/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1173\n",
            "Epoch 25/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1214\n",
            "Epoch 26/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1144\n",
            "Epoch 27/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1155\n",
            "Epoch 28/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1131\n",
            "Epoch 29/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1114\n",
            "Epoch 30/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1108\n",
            "Epoch 31/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1126\n",
            "Epoch 32/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1086\n",
            "Epoch 33/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1058\n",
            "Epoch 34/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1027\n",
            "Epoch 35/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1024\n",
            "Epoch 36/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1030\n",
            "Epoch 37/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.1013\n",
            "Epoch 38/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.0983\n",
            "Epoch 39/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.0984\n",
            "Epoch 40/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.0962\n",
            "Epoch 41/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.0945\n",
            "Epoch 42/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.0960\n",
            "Epoch 43/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.0973\n",
            "Epoch 44/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.0955\n",
            "Epoch 45/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.0915\n",
            "Epoch 46/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.0886\n",
            "Epoch 47/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.0921\n",
            "Epoch 48/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.0888\n",
            "Epoch 49/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.0887\n",
            "Epoch 50/50\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 0.0848\n",
            "0.9393939393939394 Was the accuracy when the train data size was 355\n",
            "Train data size:  360\n",
            "Epoch 1/50\n",
            "360/360 [==============================] - 2s 4ms/step - loss: 0.6388\n",
            "Epoch 2/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.5251\n",
            "Epoch 3/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.4323\n",
            "Epoch 4/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.3592\n",
            "Epoch 5/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.3027\n",
            "Epoch 6/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.2632\n",
            "Epoch 7/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.2330\n",
            "Epoch 8/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.2091\n",
            "Epoch 9/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1898\n",
            "Epoch 10/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1788\n",
            "Epoch 11/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1656\n",
            "Epoch 12/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1597\n",
            "Epoch 13/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1521\n",
            "Epoch 14/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1468\n",
            "Epoch 15/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1407\n",
            "Epoch 16/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1386\n",
            "Epoch 17/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1338\n",
            "Epoch 18/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1298\n",
            "Epoch 19/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1301\n",
            "Epoch 20/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1228\n",
            "Epoch 21/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1229\n",
            "Epoch 22/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1213\n",
            "Epoch 23/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1183\n",
            "Epoch 24/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1164\n",
            "Epoch 25/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1136\n",
            "Epoch 26/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1115\n",
            "Epoch 27/50\n",
            "360/360 [==============================] - 1s 3ms/step - loss: 0.1114\n",
            "Epoch 28/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1066\n",
            "Epoch 29/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1076\n",
            "Epoch 30/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1078\n",
            "Epoch 31/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1059\n",
            "Epoch 32/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1030\n",
            "Epoch 33/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.1009\n",
            "Epoch 34/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0991\n",
            "Epoch 35/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0997\n",
            "Epoch 36/50\n",
            "360/360 [==============================] - 1s 3ms/step - loss: 0.0973\n",
            "Epoch 37/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0974\n",
            "Epoch 38/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0937\n",
            "Epoch 39/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0960\n",
            "Epoch 40/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0935\n",
            "Epoch 41/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0899\n",
            "Epoch 42/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0901\n",
            "Epoch 43/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0895\n",
            "Epoch 44/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0875\n",
            "Epoch 45/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0886\n",
            "Epoch 46/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0902\n",
            "Epoch 47/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0893\n",
            "Epoch 48/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0853\n",
            "Epoch 49/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0855\n",
            "Epoch 50/50\n",
            "360/360 [==============================] - 1s 4ms/step - loss: 0.0848\n",
            "0.9346733668341708 Was the accuracy when the train data size was 360\n",
            "Train data size:  365\n",
            "Epoch 1/50\n",
            "365/365 [==============================] - 2s 4ms/step - loss: 0.6223\n",
            "Epoch 2/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.5195\n",
            "Epoch 3/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.4298\n",
            "Epoch 4/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.3571\n",
            "Epoch 5/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.3004\n",
            "Epoch 6/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.2573\n",
            "Epoch 7/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.2263\n",
            "Epoch 8/50\n",
            "365/365 [==============================] - 1s 3ms/step - loss: 0.2019\n",
            "Epoch 9/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1863\n",
            "Epoch 10/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1730\n",
            "Epoch 11/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1612\n",
            "Epoch 12/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1528\n",
            "Epoch 13/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1468\n",
            "Epoch 14/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1400\n",
            "Epoch 15/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1362\n",
            "Epoch 16/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1317\n",
            "Epoch 17/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1283\n",
            "Epoch 18/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1247\n",
            "Epoch 19/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1212\n",
            "Epoch 20/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1196\n",
            "Epoch 21/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1168\n",
            "Epoch 22/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1131\n",
            "Epoch 23/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1128\n",
            "Epoch 24/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1089\n",
            "Epoch 25/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1076\n",
            "Epoch 26/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1083\n",
            "Epoch 27/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1068\n",
            "Epoch 28/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0995\n",
            "Epoch 29/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1050\n",
            "Epoch 30/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0997\n",
            "Epoch 31/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.1000\n",
            "Epoch 32/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0986\n",
            "Epoch 33/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0982\n",
            "Epoch 34/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0934\n",
            "Epoch 35/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0956\n",
            "Epoch 36/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0946\n",
            "Epoch 37/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0913\n",
            "Epoch 38/50\n",
            "365/365 [==============================] - 1s 3ms/step - loss: 0.0928\n",
            "Epoch 39/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0891\n",
            "Epoch 40/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0913\n",
            "Epoch 41/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0856\n",
            "Epoch 42/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0895\n",
            "Epoch 43/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0875\n",
            "Epoch 44/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0902\n",
            "Epoch 45/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0875\n",
            "Epoch 46/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0819\n",
            "Epoch 47/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0847\n",
            "Epoch 48/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0844\n",
            "Epoch 49/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0817\n",
            "Epoch 50/50\n",
            "365/365 [==============================] - 1s 4ms/step - loss: 0.0845\n",
            "0.9587628865979382 Was the accuracy when the train data size was 365\n",
            "Train data size:  370\n",
            "Epoch 1/50\n",
            "370/370 [==============================] - 2s 4ms/step - loss: 0.5957\n",
            "Epoch 2/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.4983\n",
            "Epoch 3/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.4142\n",
            "Epoch 4/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.3460\n",
            "Epoch 5/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.2916\n",
            "Epoch 6/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.2483\n",
            "Epoch 7/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.2173\n",
            "Epoch 8/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1960\n",
            "Epoch 9/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1784\n",
            "Epoch 10/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1660\n",
            "Epoch 11/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1568\n",
            "Epoch 12/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1488\n",
            "Epoch 13/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1436\n",
            "Epoch 14/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1360\n",
            "Epoch 15/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1334\n",
            "Epoch 16/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1288\n",
            "Epoch 17/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1270\n",
            "Epoch 18/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1232\n",
            "Epoch 19/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1179\n",
            "Epoch 20/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1182\n",
            "Epoch 21/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1159\n",
            "Epoch 22/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1160\n",
            "Epoch 23/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1106\n",
            "Epoch 24/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1110\n",
            "Epoch 25/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1068\n",
            "Epoch 26/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1074\n",
            "Epoch 27/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1053\n",
            "Epoch 28/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1032\n",
            "Epoch 29/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0995\n",
            "Epoch 30/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1018\n",
            "Epoch 31/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.1006\n",
            "Epoch 32/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0982\n",
            "Epoch 33/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0974\n",
            "Epoch 34/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0924\n",
            "Epoch 35/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0941\n",
            "Epoch 36/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0935\n",
            "Epoch 37/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0907\n",
            "Epoch 38/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0901\n",
            "Epoch 39/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0906\n",
            "Epoch 40/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0890\n",
            "Epoch 41/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0858\n",
            "Epoch 42/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0870\n",
            "Epoch 43/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0856\n",
            "Epoch 44/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0837\n",
            "Epoch 45/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0845\n",
            "Epoch 46/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0811\n",
            "Epoch 47/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0822\n",
            "Epoch 48/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0799\n",
            "Epoch 49/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0788\n",
            "Epoch 50/50\n",
            "370/370 [==============================] - 1s 4ms/step - loss: 0.0777\n",
            "0.9637305699481866 Was the accuracy when the train data size was 370\n",
            "Train data size:  375\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6756\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.5547\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.4610\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3830\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3213\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2737\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2364\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2132\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1928\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1781\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1646\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1571\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1511\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1444\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1372\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1372\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1310\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1286\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1283\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1239\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1217\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1176\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1158\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1139\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1121\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1095\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1055\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1075\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1037\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1040\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.1011\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0995\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0984\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0974\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0952\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0958\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0949\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0911\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0930\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0884\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0919\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0881\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0859\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0868\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0858\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0822\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0841\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0809\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0861\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0787\n",
            "0.916256157635468 Was the accuracy when the train data size was 375\n",
            "Train data size:  380\n",
            "Epoch 1/50\n",
            "380/380 [==============================] - 2s 4ms/step - loss: 0.6036\n",
            "Epoch 2/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.5031\n",
            "Epoch 3/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.4132\n",
            "Epoch 4/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.3454\n",
            "Epoch 5/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.2889\n",
            "Epoch 6/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.2494\n",
            "Epoch 7/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.2168\n",
            "Epoch 8/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1939\n",
            "Epoch 9/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1810\n",
            "Epoch 10/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1656\n",
            "Epoch 11/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1583\n",
            "Epoch 12/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1523\n",
            "Epoch 13/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1459\n",
            "Epoch 14/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1407\n",
            "Epoch 15/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1362\n",
            "Epoch 16/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1332\n",
            "Epoch 17/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1313\n",
            "Epoch 18/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1278\n",
            "Epoch 19/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1242\n",
            "Epoch 20/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1186\n",
            "Epoch 21/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1204\n",
            "Epoch 22/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1195\n",
            "Epoch 23/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1130\n",
            "Epoch 24/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1120\n",
            "Epoch 25/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1096\n",
            "Epoch 26/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1108\n",
            "Epoch 27/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1084\n",
            "Epoch 28/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1086\n",
            "Epoch 29/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1060\n",
            "Epoch 30/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1035\n",
            "Epoch 31/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1029\n",
            "Epoch 32/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.1015\n",
            "Epoch 33/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.0989\n",
            "Epoch 34/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.0976\n",
            "Epoch 35/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.0989\n",
            "Epoch 36/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.0967\n",
            "Epoch 37/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.0949\n",
            "Epoch 38/50\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0927\n",
            "Epoch 39/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.0932\n",
            "Epoch 40/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.0918\n",
            "Epoch 41/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.0920\n",
            "Epoch 42/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.0906\n",
            "Epoch 43/50\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0894\n",
            "Epoch 44/50\n",
            "380/380 [==============================] - 1s 3ms/step - loss: 0.0890\n",
            "Epoch 45/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.0896\n",
            "Epoch 46/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.0866\n",
            "Epoch 47/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.0867\n",
            "Epoch 48/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.0844\n",
            "Epoch 49/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.0856\n",
            "Epoch 50/50\n",
            "380/380 [==============================] - 1s 4ms/step - loss: 0.0861\n",
            "0.9393939393939394 Was the accuracy when the train data size was 380\n",
            "Train data size:  385\n",
            "Epoch 1/50\n",
            "385/385 [==============================] - 2s 4ms/step - loss: 0.7243\n",
            "Epoch 2/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.5708\n",
            "Epoch 3/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.4741\n",
            "Epoch 4/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.3945\n",
            "Epoch 5/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.3287\n",
            "Epoch 6/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.2795\n",
            "Epoch 7/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.2424\n",
            "Epoch 8/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.2154\n",
            "Epoch 9/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1967\n",
            "Epoch 10/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1810\n",
            "Epoch 11/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1687\n",
            "Epoch 12/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1597\n",
            "Epoch 13/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1537\n",
            "Epoch 14/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1477\n",
            "Epoch 15/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1399\n",
            "Epoch 16/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1390\n",
            "Epoch 17/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1318\n",
            "Epoch 18/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1294\n",
            "Epoch 19/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1263\n",
            "Epoch 20/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1246\n",
            "Epoch 21/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1233\n",
            "Epoch 22/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1184\n",
            "Epoch 23/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1152\n",
            "Epoch 24/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1180\n",
            "Epoch 25/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1141\n",
            "Epoch 26/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1111\n",
            "Epoch 27/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1119\n",
            "Epoch 28/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1098\n",
            "Epoch 29/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1086\n",
            "Epoch 30/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1048\n",
            "Epoch 31/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1068\n",
            "Epoch 32/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1044\n",
            "Epoch 33/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1032\n",
            "Epoch 34/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1044\n",
            "Epoch 35/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1003\n",
            "Epoch 36/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.1004\n",
            "Epoch 37/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.0988\n",
            "Epoch 38/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.0970\n",
            "Epoch 39/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.0947\n",
            "Epoch 40/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.0943\n",
            "Epoch 41/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.0931\n",
            "Epoch 42/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.0913\n",
            "Epoch 43/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.0929\n",
            "Epoch 44/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.0917\n",
            "Epoch 45/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.0898\n",
            "Epoch 46/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.0903\n",
            "Epoch 47/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.0909\n",
            "Epoch 48/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.0899\n",
            "Epoch 49/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.0843\n",
            "Epoch 50/50\n",
            "385/385 [==============================] - 1s 4ms/step - loss: 0.0871\n",
            "0.9393939393939394 Was the accuracy when the train data size was 385\n",
            "Train data size:  390\n",
            "Epoch 1/50\n",
            "390/390 [==============================] - 2s 4ms/step - loss: 0.6504\n",
            "Epoch 2/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.5437\n",
            "Epoch 3/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.4521\n",
            "Epoch 4/50\n",
            "390/390 [==============================] - 2s 4ms/step - loss: 0.3746\n",
            "Epoch 5/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.3119\n",
            "Epoch 6/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.2655\n",
            "Epoch 7/50\n",
            "390/390 [==============================] - 1s 3ms/step - loss: 0.2302\n",
            "Epoch 8/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.2054\n",
            "Epoch 9/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1872\n",
            "Epoch 10/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1740\n",
            "Epoch 11/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1648\n",
            "Epoch 12/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1550\n",
            "Epoch 13/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1494\n",
            "Epoch 14/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1441\n",
            "Epoch 15/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1386\n",
            "Epoch 16/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1354\n",
            "Epoch 17/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1285\n",
            "Epoch 18/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1297\n",
            "Epoch 19/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1237\n",
            "Epoch 20/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1256\n",
            "Epoch 21/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1224\n",
            "Epoch 22/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1198\n",
            "Epoch 23/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1152\n",
            "Epoch 24/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1153\n",
            "Epoch 25/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1116\n",
            "Epoch 26/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1174\n",
            "Epoch 27/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1098\n",
            "Epoch 28/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1135\n",
            "Epoch 29/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1055\n",
            "Epoch 30/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1102\n",
            "Epoch 31/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1043\n",
            "Epoch 32/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1072\n",
            "Epoch 33/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1033\n",
            "Epoch 34/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1029\n",
            "Epoch 35/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1009\n",
            "Epoch 36/50\n",
            "390/390 [==============================] - 2s 4ms/step - loss: 0.1019\n",
            "Epoch 37/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.0995\n",
            "Epoch 38/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.0930\n",
            "Epoch 39/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.1017\n",
            "Epoch 40/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.0966\n",
            "Epoch 41/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.0946\n",
            "Epoch 42/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.0923\n",
            "Epoch 43/50\n",
            "390/390 [==============================] - 2s 4ms/step - loss: 0.0907\n",
            "Epoch 44/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.0929\n",
            "Epoch 45/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.0911\n",
            "Epoch 46/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.0911\n",
            "Epoch 47/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.0908\n",
            "Epoch 48/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.0892\n",
            "Epoch 49/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.0898\n",
            "Epoch 50/50\n",
            "390/390 [==============================] - 1s 4ms/step - loss: 0.0895\n",
            "0.9393939393939394 Was the accuracy when the train data size was 390\n",
            "Train data size:  395\n",
            "Epoch 1/50\n",
            "395/395 [==============================] - 2s 4ms/step - loss: 0.5777\n",
            "Epoch 2/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.4798\n",
            "Epoch 3/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.3966\n",
            "Epoch 4/50\n",
            "395/395 [==============================] - 1s 3ms/step - loss: 0.3295\n",
            "Epoch 5/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.2777\n",
            "Epoch 6/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.2361\n",
            "Epoch 7/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.2117\n",
            "Epoch 8/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1905\n",
            "Epoch 9/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1752\n",
            "Epoch 10/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1633\n",
            "Epoch 11/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1546\n",
            "Epoch 12/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1479\n",
            "Epoch 13/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1395\n",
            "Epoch 14/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1347\n",
            "Epoch 15/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1317\n",
            "Epoch 16/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1281\n",
            "Epoch 17/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1246\n",
            "Epoch 18/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1194\n",
            "Epoch 19/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1185\n",
            "Epoch 20/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1154\n",
            "Epoch 21/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1137\n",
            "Epoch 22/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1119\n",
            "Epoch 23/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1107\n",
            "Epoch 24/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1060\n",
            "Epoch 25/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1091\n",
            "Epoch 26/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1046\n",
            "Epoch 27/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1011\n",
            "Epoch 28/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1012\n",
            "Epoch 29/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1010\n",
            "Epoch 30/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.1004\n",
            "Epoch 31/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0980\n",
            "Epoch 32/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0951\n",
            "Epoch 33/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0956\n",
            "Epoch 34/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0944\n",
            "Epoch 35/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0926\n",
            "Epoch 36/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0900\n",
            "Epoch 37/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0911\n",
            "Epoch 38/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0883\n",
            "Epoch 39/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0908\n",
            "Epoch 40/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0893\n",
            "Epoch 41/50\n",
            "395/395 [==============================] - 1s 3ms/step - loss: 0.0890\n",
            "Epoch 42/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0848\n",
            "Epoch 43/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0872\n",
            "Epoch 44/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0856\n",
            "Epoch 45/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0840\n",
            "Epoch 46/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0810\n",
            "Epoch 47/50\n",
            "395/395 [==============================] - 1s 3ms/step - loss: 0.0865\n",
            "Epoch 48/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0816\n",
            "Epoch 49/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0820\n",
            "Epoch 50/50\n",
            "395/395 [==============================] - 1s 4ms/step - loss: 0.0809\n",
            "0.9637305699481866 Was the accuracy when the train data size was 395\n",
            "Train data size:  400\n",
            "Epoch 1/50\n",
            "400/400 [==============================] - 2s 4ms/step - loss: 0.7079\n",
            "Epoch 2/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.5750\n",
            "Epoch 3/50\n",
            "400/400 [==============================] - 2s 4ms/step - loss: 0.4775\n",
            "Epoch 4/50\n",
            "400/400 [==============================] - 2s 4ms/step - loss: 0.3993\n",
            "Epoch 5/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.3348\n",
            "Epoch 6/50\n",
            "400/400 [==============================] - 2s 4ms/step - loss: 0.2864\n",
            "Epoch 7/50\n",
            "400/400 [==============================] - 2s 4ms/step - loss: 0.2506\n",
            "Epoch 8/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.2228\n",
            "Epoch 9/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.2022\n",
            "Epoch 10/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1895\n",
            "Epoch 11/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1777\n",
            "Epoch 12/50\n",
            "400/400 [==============================] - 2s 4ms/step - loss: 0.1672\n",
            "Epoch 13/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1601\n",
            "Epoch 14/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1529\n",
            "Epoch 15/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1488\n",
            "Epoch 16/50\n",
            "400/400 [==============================] - 2s 4ms/step - loss: 0.1441\n",
            "Epoch 17/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1398\n",
            "Epoch 18/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1354\n",
            "Epoch 19/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1351\n",
            "Epoch 20/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1302\n",
            "Epoch 21/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1276\n",
            "Epoch 22/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1262\n",
            "Epoch 23/50\n",
            "400/400 [==============================] - 2s 4ms/step - loss: 0.1243\n",
            "Epoch 24/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1231\n",
            "Epoch 25/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1194\n",
            "Epoch 26/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1192\n",
            "Epoch 27/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1152\n",
            "Epoch 28/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1152\n",
            "Epoch 29/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1051\n",
            "Epoch 30/50\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.1127\n",
            "Epoch 31/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1077\n",
            "Epoch 32/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1079\n",
            "Epoch 33/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1061\n",
            "Epoch 34/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1055\n",
            "Epoch 35/50\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.1049\n",
            "Epoch 36/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1031\n",
            "Epoch 37/50\n",
            "400/400 [==============================] - 2s 4ms/step - loss: 0.0998\n",
            "Epoch 38/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.1006\n",
            "Epoch 39/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.0968\n",
            "Epoch 40/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.0990\n",
            "Epoch 41/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.0961\n",
            "Epoch 42/50\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.0963\n",
            "Epoch 43/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.0926\n",
            "Epoch 44/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.0917\n",
            "Epoch 45/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.0942\n",
            "Epoch 46/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.0945\n",
            "Epoch 47/50\n",
            "400/400 [==============================] - 2s 4ms/step - loss: 0.0929\n",
            "Epoch 48/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.0904\n",
            "Epoch 49/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.0895\n",
            "Epoch 50/50\n",
            "400/400 [==============================] - 1s 4ms/step - loss: 0.0869\n",
            "0.9441624365482233 Was the accuracy when the train data size was 400\n"
          ]
        }
      ],
      "source": [
        "score_dict = {0: 0}\n",
        "\n",
        "for j in range(5, 401, 5):\n",
        "    print('Train data size: ', j)\n",
        "    x = X_train[0:j, :]\n",
        "    y = Y_train[0:j]\n",
        "\n",
        "    \n",
        "    classifier = Sequential() # Initialising the ANN\n",
        "    classifier.add(Dense(units = 25, activation = 'sigmoid', input_dim = 30))\n",
        "    classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "    classifier.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy')\n",
        "    classifier.fit(x, y, batch_size = 1, epochs = 50)\n",
        "\n",
        "    Y_pred = classifier.predict(X_test)\n",
        "    Y_pred = [ 1 if y>=0.5 else 0 for y in Y_pred ]\n",
        "    \n",
        "    score_dict[j] = f1_score(Y_pred, Y_test)\n",
        "    print(f1_score(Y_pred, Y_test), 'Was the accuracy when the train data size was', j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CsU2yWHXMnoN",
        "outputId": "10de1fea-2c2f-4f9e-ca00-e90ecdf2cd05"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_list = sorted(score_dict.items())\n",
        "x_cord, y_cord = zip(*plot_list)\n",
        "plt.plot(x_cord, y_cord)\n",
        "plt.yticks(np.arange(min(y_cord), max(y_cord) + 0.05, 0.05))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XHFNqpeiMpng",
        "outputId": "230f66b5-ea0d-4cee-a3f7-dfb269f78565"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0, 0),\n",
              " (5, 0.714828897338403),\n",
              " (10, 0.714828897338403),\n",
              " (15, 0.7175572519083969),\n",
              " (20, 0.714828897338403),\n",
              " (25, 0.7203065134099617),\n",
              " (30, 0.7768595041322314),\n",
              " (35, 0.8584474885844748),\n",
              " (40, 0.8867924528301886),\n",
              " (45, 0.8826291079812207),\n",
              " (50, 0.9073170731707317),\n",
              " (55, 0.8867924528301886),\n",
              " (60, 0.8942307692307693),\n",
              " (65, 0.9261083743842364),\n",
              " (70, 0.9207920792079208),\n",
              " (75, 0.9073170731707317),\n",
              " (80, 0.934010152284264),\n",
              " (85, 0.934010152284264),\n",
              " (90, 0.9387755102040817),\n",
              " (95, 0.9489795918367346),\n",
              " (100, 0.9393939393939394),\n",
              " (105, 0.934010152284264),\n",
              " (110, 0.9538461538461538),\n",
              " (115, 0.9484536082474226),\n",
              " (120, 0.962962962962963),\n",
              " (125, 0.9381443298969071),\n",
              " (130, 0.9680851063829787),\n",
              " (135, 0.9489795918367346),\n",
              " (140, 0.962962962962963),\n",
              " (145, 0.9441624365482233),\n",
              " (150, 0.9435897435897436),\n",
              " (155, 0.9393939393939394),\n",
              " (160, 0.9393939393939394),\n",
              " (165, 0.9441624365482233),\n",
              " (170, 0.9587628865979382),\n",
              " (175, 0.9346733668341708),\n",
              " (180, 0.9489795918367346),\n",
              " (185, 0.9489795918367346),\n",
              " (190, 0.9441624365482233),\n",
              " (195, 0.9441624365482233),\n",
              " (200, 0.9441624365482233),\n",
              " (205, 0.9393939393939394),\n",
              " (210, 0.9587628865979382),\n",
              " (215, 0.9393939393939394),\n",
              " (220, 0.9253731343283582),\n",
              " (225, 0.9489795918367346),\n",
              " (230, 0.9441624365482233),\n",
              " (235, 0.93),\n",
              " (240, 0.93),\n",
              " (245, 0.9393939393939394),\n",
              " (250, 0.93),\n",
              " (255, 0.9393939393939394),\n",
              " (260, 0.9538461538461538),\n",
              " (265, 0.9253731343283582),\n",
              " (270, 0.9346733668341708),\n",
              " (275, 0.9253731343283582),\n",
              " (280, 0.9393939393939394),\n",
              " (285, 0.9253731343283582),\n",
              " (290, 0.9441624365482233),\n",
              " (295, 0.9346733668341708),\n",
              " (300, 0.9538461538461538),\n",
              " (305, 0.9538461538461538),\n",
              " (310, 0.9587628865979382),\n",
              " (315, 0.9207920792079208),\n",
              " (320, 0.9538461538461538),\n",
              " (325, 0.9346733668341708),\n",
              " (330, 0.9441624365482233),\n",
              " (335, 0.9073170731707317),\n",
              " (340, 0.93),\n",
              " (345, 0.9207920792079208),\n",
              " (350, 0.9207920792079208),\n",
              " (355, 0.9393939393939394),\n",
              " (360, 0.9346733668341708),\n",
              " (365, 0.9587628865979382),\n",
              " (370, 0.9637305699481866),\n",
              " (375, 0.916256157635468),\n",
              " (380, 0.9393939393939394),\n",
              " (385, 0.9393939393939394),\n",
              " (390, 0.9393939393939394),\n",
              " (395, 0.9637305699481866),\n",
              " (400, 0.9441624365482233)]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plot_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzRxURICgV0X"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di9SmndFYGqv"
      },
      "source": [
        "#K-folded DNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TEAONCuYNeD"
      },
      "outputs": [],
      "source": [
        "\n",
        "FOLDS = 10\n",
        "kf = createKFold(FOLDS)\n",
        "\n",
        "cum_score = 0;\n",
        "x = data[:, :-1] # for all but last column\n",
        "y = data[:, -1] # for last column\n",
        "\n",
        "print('The scores per run are:')\n",
        "for train_index, test_index in kf.split(x):\n",
        "    print('Train data size: ', j)\n",
        "    X_train = x[train_index]\n",
        "    Y_train = y[train_index]\n",
        "    X_test = x[test_index]\n",
        "    Y_test = y[test_index]\n",
        "\n",
        "    \n",
        "    classifier = Sequential() # Initialising the ANN\n",
        "    classifier.add(Dense(units = 16, activation = 'relu', input_dim = 30))\n",
        "    classifier.add(Dense(units = 8, activation = 'relu'))\n",
        "    classifier.add(Dense(units = 6, activation = 'relu'))\n",
        "    classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "    classifier.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy')\n",
        "    classifier.fit(X_train, Y_train, batch_size = 1, epochs = 50)\n",
        "\n",
        "    Y_pred = classifier.predict(X_test)\n",
        "    Y_pred = [ 1 if y>=0.5 else 0 for y in Y_pred ]\n",
        "    \n",
        "    cum_score += f1_score(Y_pred, Y_test)\n",
        "    print(f1_score(Y_pred, Y_test)\n",
        "print(\"Accuracy (mean): \", cum_score / FOLDS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIpdvaNMcWaO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR-q4z7wZNyd"
      },
      "outputs": [],
      "source": [
        "\n",
        "kf = createKFold(FOLDS)\n",
        "\n",
        "cum_score = 0;\n",
        "\n",
        "for train_index, test_index in kf.split(x):\n",
        "        clf_bayes.fit(x[train_index], y[train_index])\n",
        "\n",
        "        cum_score = cum_score + f1_score(y[test_index], clf_bayes.predict(x[test_index]))\n",
        "\n",
        "        print(f1_score(y[test_index], clf_bayes.predict(x[test_index])))\n",
        "\n",
        "    print(\"Accuracy (mean): \", cum_score / FOLDS)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Deep network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}